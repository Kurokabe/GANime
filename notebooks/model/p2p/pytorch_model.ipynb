{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a924cdbc-6e61-454d-b9cb-3c88c31e5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1, 2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8079ac97-bdc2-4d48-9789-d5f960079172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73552332-5f75-43d7-853a-90960f77fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size=100\n",
    "\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, n_layers, batch_size):\n",
    "        super(lstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm = nn.ModuleList([nn.LSTMCell(hidden_size, hidden_size) for i in range(self.n_layers)])\n",
    "        self.output = nn.Sequential(\n",
    "                nn.Linear(hidden_size, output_size),\n",
    "                #nn.BatchNorm1d(output_size),\n",
    "                nn.Tanh())\n",
    "        self.hidden = self.init_hidden(self.batch_size)\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        hidden = []\n",
    "        for i in range(self.n_layers):\n",
    "            hidden.append((Variable(torch.zeros(batch_size, self.hidden_size).to(device)),\n",
    "                           Variable(torch.zeros(batch_size, self.hidden_size).to(device))))\n",
    "        self.hidden = hidden\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden_(self, batch_size):\n",
    "        hidden = []\n",
    "        for i in range(self.n_layers):\n",
    "            hidden.append((Variable(torch.zeros(batch_size, self.hidden_size).to(device)),\n",
    "                           Variable(torch.zeros(batch_size, self.hidden_size).to(device))))\n",
    "        self.hidden = hidden\n",
    "        #return hidden\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embed(input.view(-1, self.input_size))\n",
    "        h_in = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            self.hidden[i] = self.lstm[i](h_in, self.hidden[i])\n",
    "            h_in = self.hidden[i][0]\n",
    "\n",
    "        return self.output(h_in)\n",
    "\n",
    "class gaussian_lstm(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, n_layers, batch_size):\n",
    "        super(gaussian_lstm, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.embed = nn.Linear(input_size, hidden_size)\n",
    "        self.lstm = nn.ModuleList([nn.LSTMCell(hidden_size, hidden_size) for i in range(self.n_layers)])\n",
    "        self.mu_net = nn.Linear(hidden_size, output_size)\n",
    "        self.logvar_net = nn.Linear(hidden_size, output_size)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        hidden = []\n",
    "        for i in range(self.n_layers):\n",
    "            hidden.append((Variable(torch.zeros(batch_size, self.hidden_size).to(device)),\n",
    "                           Variable(torch.zeros(batch_size, self.hidden_size).to(device))))\n",
    "        self.hidden = hidden\n",
    "        return hidden\n",
    "\n",
    "    def init_hidden_(self):\n",
    "        hidden = []\n",
    "        for i in range(self.n_layers):\n",
    "            hidden.append((Variable(torch.zeros(self.batch_size, self.hidden_size).to(device)),\n",
    "                           Variable(torch.zeros(self.batch_size, self.hidden_size).to(device))))\n",
    "        self.hidden = hidden\n",
    "        #return hidden\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        logvar = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(logvar.data.new(logvar.size()).normal_())\n",
    "        #return eps.add_(mu)\n",
    "        #return eps.mul(logvar)\n",
    "        return eps.mul(logvar).add_(mu)\n",
    "\n",
    "    def forward(self, input):\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        embedded = self.embed(input.view(-1, self.input_size))\n",
    "        h_in = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            self.hidden[i] = self.lstm[i](h_in, self.hidden[i])\n",
    "            h_in = self.hidden[i][0]\n",
    "        mu = self.mu_net(h_in)\n",
    "        logvar = self.logvar_net(h_in)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee105dff-45ff-48bf-bbaa-a98414b81b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dcgan_conv(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(dcgan_conv, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                nn.Conv2d(nin, nout, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nout),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class dcgan_upconv(nn.Module):\n",
    "    def __init__(self, nin, nout):\n",
    "        super(dcgan_upconv, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "                nn.ConvTranspose2d(nin, nout, 4, 2, 1),\n",
    "                nn.BatchNorm2d(nout),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, dim, nc=1):\n",
    "        super(encoder, self).__init__()\n",
    "        self.dim = dim\n",
    "        nf = 64\n",
    "        # input is (nc) x 64 x 64\n",
    "        self.c1 = dcgan_conv(nc, nf)\n",
    "        # state size. (nf) x 32 x 32\n",
    "        self.c2 = dcgan_conv(nf, nf * 2)\n",
    "        # state size. (nf*2) x 16 x 16\n",
    "        self.c3 = dcgan_conv(nf * 2, nf * 4)\n",
    "        # state size. (nf*4) x 8 x 8\n",
    "        self.c4 = dcgan_conv(nf * 4, nf * 8)\n",
    "        # state size. (nf*8) x 4 x 4\n",
    "        self.c5 = nn.Sequential(\n",
    "                nn.Conv2d(nf * 8, dim, 4, 1, 0),\n",
    "                nn.BatchNorm2d(dim),\n",
    "                nn.Tanh()\n",
    "                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        h1 = self.c1(input)\n",
    "        h2 = self.c2(h1)\n",
    "        h3 = self.c3(h2)\n",
    "        h4 = self.c4(h3)\n",
    "        h5 = self.c5(h4)\n",
    "        return h5.view(-1, self.dim), [h1, h2, h3, h4]\n",
    "\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self, dim, nc=1):\n",
    "        super(decoder, self).__init__()\n",
    "        self.dim = dim\n",
    "        nf = 64\n",
    "        self.upc1 = nn.Sequential(\n",
    "                # input is Z, going into a convolution\n",
    "                nn.ConvTranspose2d(dim, nf * 8, 4, 1, 0),\n",
    "                nn.BatchNorm2d(nf * 8),\n",
    "                nn.LeakyReLU(0.2)\n",
    "                )\n",
    "        # state size. (nf*8) x 4 x 4\n",
    "        self.upc2 = dcgan_upconv(nf * 8 * 2, nf * 4)\n",
    "        # state size. (nf*4) x 8 x 8\n",
    "        self.upc3 = dcgan_upconv(nf * 4 * 2, nf * 2)\n",
    "        # state size. (nf*2) x 16 x 16\n",
    "        self.upc4 = dcgan_upconv(nf * 2 * 2, nf)\n",
    "        # state size. (nf) x 32 x 32\n",
    "        self.upc5 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(nf * 2, nc, 4, 2, 1),\n",
    "                nn.Sigmoid()\n",
    "                # state size. (nc) x 64 x 64\n",
    "                )\n",
    "\n",
    "    def forward(self, input):\n",
    "        vec, skip = input \n",
    "        d1 = self.upc1(vec.view(-1, self.dim, 1, 1))\n",
    "        d2 = self.upc2(torch.cat([d1, skip[3]], 1))\n",
    "        d3 = self.upc3(torch.cat([d2, skip[2]], 1))\n",
    "        d4 = self.upc4(torch.cat([d3, skip[1]], 1))\n",
    "        output = self.upc5(torch.cat([d4, skip[0]], 1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cce372-127f-47cd-8c13-37ba2bc36a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLCriterion(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, mu1, logvar1, mu2, logvar2):\n",
    "        \"\"\"KL( N(mu_1, sigma2_1) || N(mu_2, sigma2_2))\"\"\"\n",
    "        sigma1 = logvar1.mul(0.5).exp() \n",
    "        sigma2 = logvar2.mul(0.5).exp() \n",
    "        kld = torch.log(sigma2/sigma1) + (torch.exp(logvar1) + (mu1 - mu2)**2)/(2*torch.exp(logvar2)) - 1/2\n",
    "        return kld.sum() / self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d755453-1f8f-4689-94b5-eb1c1d34d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1 or classname.find(\"Linear\") != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5418baa-1e72-4c70-bde8-d346db000a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class P2PModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        batch_size=100,\n",
    "        channels=1,\n",
    "        g_dim=128,\n",
    "        z_dim=10,\n",
    "        rnn_size=256,\n",
    "        prior_rnn_layers=1,\n",
    "        posterior_rnn_layers=1,\n",
    "        predictor_rnn_layers=2,\n",
    "        learning_rate=0.002,\n",
    "        skip_prob: float = 0.1,\n",
    "        n_past: int = 1,\n",
    "        last_frame_skip: bool = False,\n",
    "        beta: float = 0.0001,\n",
    "        weight_align: float = 0.1,\n",
    "        weight_cpc: float = 100,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.channels = channels\n",
    "        self.g_dim = g_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.rnn_size = rnn_size\n",
    "        self.prior_rnn_layers = prior_rnn_layers\n",
    "        self.posterior_rnn_layers = posterior_rnn_layers\n",
    "        self.predictor_rnn_layers = predictor_rnn_layers\n",
    "        \n",
    "        # Training parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.skip_prob = skip_prob\n",
    "        self.n_past = n_past\n",
    "        self.last_frame_skip = last_frame_skip\n",
    "        self.beta = beta\n",
    "        self.weight_align = weight_align\n",
    "        self.weight_cpc = weight_cpc\n",
    "\n",
    "        # LSTMs\n",
    "        self.frame_predictor = lstm(\n",
    "            self.g_dim + self.z_dim + 1 + 1,\n",
    "            self.g_dim,\n",
    "            self.rnn_size,\n",
    "            self.predictor_rnn_layers,\n",
    "            self.batch_size,\n",
    "        )\n",
    "        self.posterior = gaussian_lstm(\n",
    "            self.g_dim + self.g_dim + 1 + 1,\n",
    "            self.z_dim,\n",
    "            self.rnn_size,\n",
    "            self.posterior_rnn_layers,\n",
    "            self.batch_size,\n",
    "        )\n",
    "        self.prior = gaussian_lstm(\n",
    "            self.g_dim + self.g_dim + 1 + 1,\n",
    "            self.z_dim,\n",
    "            self.rnn_size,\n",
    "            self.prior_rnn_layers,\n",
    "            self.batch_size,\n",
    "        )\n",
    "\n",
    "        # encoder & decoder\n",
    "        self.encoder = encoder(self.g_dim, self.channels)\n",
    "        self.decoder = decoder(self.g_dim, self.channels)\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = optim.Adam\n",
    "\n",
    "        # criterions\n",
    "        self.mse_criterion = nn.MSELoss()  # recon and cpc\n",
    "        self.kl_criterion = KLCriterion(batch_size=batch_size)\n",
    "        self.align_criterion = nn.MSELoss()\n",
    "\n",
    "        self.init_weight()\n",
    "        self.init_optimizer()\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        self.frame_predictor_optimizer = self.optimizer(\n",
    "            self.frame_predictor.parameters(), lr=self.learning_rate, betas=(self.beta, 0.999)\n",
    "        )\n",
    "        self.posterior_optimizer = self.optimizer(\n",
    "            self.posterior.parameters(), lr=self.learning_rate, betas=(self.beta, 0.999)\n",
    "        )\n",
    "        self.prior_optimizer = self.optimizer(\n",
    "            self.prior.parameters(), lr=self.learning_rate, betas=(self.beta, 0.999)\n",
    "        )\n",
    "        self.encoder_optimizer = self.optimizer(\n",
    "            self.encoder.parameters(), lr=self.learning_rate, betas=(self.beta, 0.999)\n",
    "        )\n",
    "        self.decoder_optimizer = self.optimizer(\n",
    "            self.decoder.parameters(), lr=self.learning_rate, betas=(self.beta, 0.999)\n",
    "        )\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        self.frame_predictor.hidden = self.frame_predictor.init_hidden(\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        self.posterior.hidden = self.posterior.init_hidden(batch_size=batch_size)\n",
    "        self.prior.hidden = self.prior.init_hidden(batch_size=batch_size)\n",
    "\n",
    "    def init_weight(self):\n",
    "        self.frame_predictor.apply(init_weights)\n",
    "        self.posterior.apply(init_weights)\n",
    "        self.prior.apply(init_weights)\n",
    "        self.encoder.apply(init_weights)\n",
    "        self.decoder.apply(init_weights)\n",
    "\n",
    "    def get_global_descriptor(self, x, start_ix=0, cp_ix=None):\n",
    "        \"\"\"Get the global descriptor based on x, start_ix, cp_ix.\"\"\"\n",
    "        if cp_ix is None:\n",
    "            cp_ix = len(x) - 1\n",
    "        x_cp = x[cp_ix]\n",
    "        h_cp = self.encoder(x_cp)[0]  # 1 is input for skip-connection\n",
    "\n",
    "        return x_cp, h_cp\n",
    "\n",
    "    def p2p_generate(\n",
    "        self,\n",
    "        x,\n",
    "        len_output,\n",
    "        eval_cp_ix,\n",
    "        start_ix=0,\n",
    "        cp_ix=-1,\n",
    "        model_mode=\"full\",\n",
    "        skip_frame=False,\n",
    "        init_hidden=True,\n",
    "    ):\n",
    "        \"\"\"Point-to-Point Generation given input sequence. Generate *1* sample for each input sequence.\n",
    "\n",
    "        params:\n",
    "            x: input sequence\n",
    "            len_output: length of the generated sequence\n",
    "            eval_cp_ix: cp_ix of the output sequence. usually it is len_output-1\n",
    "            model_mode:\n",
    "                - full:      post then prior\n",
    "                - posterior: all use posterior\n",
    "                - prior:     all use prior\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if type(x) == tuple:\n",
    "            # h36m\n",
    "            (pose_2d, pose_3d, camera_view) = x\n",
    "            # T, bs = len(pose_3d), pose_3d[0].shape[0]\n",
    "            # x = pose_3d.view(T, bs, -1)\n",
    "            x = pose_3d\n",
    "            batch_size, coor, n_dim = x[0].shape\n",
    "            dim_shape = (coor, n_dim)\n",
    "        else:\n",
    "            batch_size, channels, h, w = x[0].shape\n",
    "            dim_shape = (channels, h, w)\n",
    "\n",
    "        # gen_seq will collect the generated frames\n",
    "        gen_seq = [x[0]]\n",
    "        x_in = x[0]\n",
    "\n",
    "        # NOTE: for visualization\n",
    "        # init lstm\n",
    "        if init_hidden:\n",
    "            self.init_hidden(batch_size=batch_size)\n",
    "\n",
    "        # get global descriptor\n",
    "        seq_len = len(x)\n",
    "        cp_ix = seq_len - 1\n",
    "        x_cp, global_z = self.get_global_descriptor(\n",
    "            x, cp_ix=cp_ix\n",
    "        )  # here global_z is h_cp\n",
    "\n",
    "        ###### time skipping\n",
    "        skip_prob = self.skip_prob\n",
    "\n",
    "        prev_i = 0\n",
    "        max_skip_count = seq_len * skip_prob\n",
    "        skip_count = 0\n",
    "        probs = np.random.uniform(0, 1, len_output - 1)\n",
    "\n",
    "        # for each sample, generate *n_eval* frames\n",
    "        for i in range(1, len_output):\n",
    "            # if np.random.uniform(0, 1) <= skip_prob and i > 1 and skip_count < max_skip_count and i != cp_ix:\n",
    "            if (\n",
    "                probs[i - 1] <= skip_prob\n",
    "                and i >= self.n_past\n",
    "                and skip_count < max_skip_count\n",
    "                and i != 1\n",
    "                and i != (len_output - 1)\n",
    "                and skip_frame\n",
    "            ):\n",
    "                skip_count += 1\n",
    "                gen_seq.append(torch.zeros_like(x_in))\n",
    "                continue\n",
    "\n",
    "            time_until_cp = (\n",
    "                torch.zeros(batch_size, 1)\n",
    "                .fill_((eval_cp_ix - i + 1) / eval_cp_ix)\n",
    "                .to(x_cp)\n",
    "            )\n",
    "            delta_time = (\n",
    "                torch.zeros(batch_size, 1).fill_((i - prev_i) / eval_cp_ix).to(x_cp)\n",
    "            )\n",
    "\n",
    "            prev_i = i\n",
    "\n",
    "            h = self.encoder(x_in)\n",
    "            # if opt.last_frame_skip or i < opt.n_past: # original\n",
    "            if self.last_frame_skip or i == 1 or i < self.n_past:\n",
    "                h, skip = h\n",
    "            else:\n",
    "                h, _ = h\n",
    "\n",
    "            h_cpaw = torch.cat([h, global_z, time_until_cp, delta_time], 1).detach()\n",
    "\n",
    "            if i < self.n_past:\n",
    "                h_target = self.encoder(x[i])[0]\n",
    "                h_target_cpaw = torch.cat(\n",
    "                    [h_target, global_z, time_until_cp, delta_time], 1\n",
    "                ).detach()\n",
    "                zt, _, _ = self.posterior(h_target_cpaw)\n",
    "                zt_p, _, _ = self.prior(h_cpaw)\n",
    "\n",
    "                if model_mode == \"posterior\" or model_mode == \"full\":\n",
    "                    self.frame_predictor(\n",
    "                        torch.cat([h, zt, time_until_cp, delta_time], 1)\n",
    "                    )\n",
    "                elif model_mode == \"prior\":\n",
    "                    self.frame_predictor(\n",
    "                        torch.cat([h, zt_p, time_until_cp, delta_time], 1)\n",
    "                    )\n",
    "\n",
    "                x_in = x[i]\n",
    "                gen_seq.append(\n",
    "                    x_in\n",
    "                )  # NOTE: gen_seq can append the decoded x_in for comparing with gt\n",
    "            else:\n",
    "                if i < len(x):  # for posterior\n",
    "                    h_target = self.encoder(x[i])[0]\n",
    "                    h_target_cpaw = torch.cat(\n",
    "                        [h_target, global_z, time_until_cp, delta_time], 1\n",
    "                    ).detach()\n",
    "                else:\n",
    "                    h_target_cpaw = h_cpaw\n",
    "\n",
    "                zt, _, _ = self.posterior(h_target_cpaw)\n",
    "                zt_p, _, _ = self.prior(h_cpaw)\n",
    "\n",
    "                if model_mode == \"posterior\":\n",
    "                    h = self.frame_predictor(\n",
    "                        torch.cat([h, zt, time_until_cp, delta_time], 1)\n",
    "                    )\n",
    "                elif model_mode == \"prior\" or model_mode == \"full\":\n",
    "                    h = self.frame_predictor(\n",
    "                        torch.cat([h, zt_p, time_until_cp, delta_time], 1)\n",
    "                    )\n",
    "\n",
    "                x_in = self.decoder([h, skip]).detach()\n",
    "                gen_seq.append(\n",
    "                    x_in\n",
    "                )  # NOTE: gen_seq can append the decoded x_in for comparing with gt\n",
    "        return gen_seq\n",
    "\n",
    "    def forward(self, x, start_ix=0, cp_ix=-1):\n",
    "        \"\"\"training\"\"\"\n",
    "        if type(x) == tuple:  # h36m # NOTE: TODO\n",
    "            (pose_2d, pose_3d, camera_view) = x\n",
    "            x = pose_3d\n",
    "\n",
    "        batch_size = x[0].shape[0]\n",
    "\n",
    "        # initialize the hidden state\n",
    "        self.init_hidden(batch_size=batch_size)\n",
    "\n",
    "        # losses\n",
    "        mse_loss = 0\n",
    "        kld_loss = 0\n",
    "        cpc_loss = 0\n",
    "        align_loss = 0\n",
    "\n",
    "        # get global descriptor\n",
    "        seq_len = len(x)\n",
    "        start_ix = 0\n",
    "        cp_ix = seq_len - 1\n",
    "        x_cp, global_z = self.get_global_descriptor(\n",
    "            x, start_ix, cp_ix\n",
    "        )  # here global_z is h_cp\n",
    "\n",
    "        # time skipping\n",
    "        skip_prob = self.skip_prob\n",
    "\n",
    "        prev_i = 0\n",
    "        max_skip_count = seq_len * skip_prob\n",
    "        skip_count = 0\n",
    "        probs = np.random.uniform(0, 1, seq_len - 1)\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            # if np.random.uniform(0, 1) <= skip_prob and i > 1 and skip_count < max_skip_count and i != cp_ix:\n",
    "            # if probs[i-1] <= skip_prob and i >= opt.n_past and skip_count < max_skip_count and i != cp_ix:\n",
    "            if (\n",
    "                probs[i - 1] <= skip_prob\n",
    "                and i >= self.n_past\n",
    "                and skip_count < max_skip_count\n",
    "                and i != 1\n",
    "                and i != cp_ix\n",
    "            ):\n",
    "                skip_count += 1\n",
    "                continue\n",
    "\n",
    "            if i > 1:\n",
    "                align_loss += self.align_criterion(h[0], h_pred)\n",
    "\n",
    "            time_until_cp = (\n",
    "                torch.zeros(batch_size, 1).fill_((cp_ix - i + 1) / cp_ix).to(x_cp)\n",
    "            )\n",
    "            delta_time = torch.zeros(batch_size, 1).fill_((i - prev_i) / cp_ix).to(x_cp)\n",
    "            prev_i = i\n",
    "\n",
    "            h = self.encoder(x[i - 1])\n",
    "            h_target = self.encoder(x[i])[0]\n",
    "\n",
    "            # if opt.last_frame_skip or i < opt.n_past: # original\n",
    "            if self.last_frame_skip or i <= self.n_past:\n",
    "                h, skip = h\n",
    "            else:\n",
    "                h = h[0]\n",
    "\n",
    "            # cp aware\n",
    "            h_cpaw = torch.cat([h, global_z, time_until_cp, delta_time], 1)\n",
    "            h_target_cpaw = torch.cat(\n",
    "                [h_target, global_z, time_until_cp, delta_time], 1\n",
    "            )\n",
    "\n",
    "            zt, mu, logvar = self.posterior(h_target_cpaw)\n",
    "            zt_p, mu_p, logvar_p = self.prior(h_cpaw)\n",
    "\n",
    "            frame_predictor_input = torch.cat([h, zt, time_until_cp, delta_time], 1)\n",
    "\n",
    "            h_pred = self.frame_predictor( frame_predictor_input)\n",
    "            x_pred = self.decoder([h_pred, skip])\n",
    "\n",
    "            # loss\n",
    "            if i == (cp_ix):  # the gen-cp-frame should be exactly as x_cp\n",
    "                h_pred_p = self.frame_predictor(\n",
    "                    torch.cat([h, zt_p, time_until_cp, delta_time], 1)\n",
    "                )\n",
    "                x_pred_p = self.decoder([h_pred_p, skip])\n",
    "                cpc_loss = self.mse_criterion(x_pred_p, x_cp)\n",
    "\n",
    "            mse_loss += self.mse_criterion(x_pred, x[i])\n",
    "            kld_loss += self.kl_criterion(mu, logvar, mu_p, logvar_p)\n",
    "\n",
    "        # backward\n",
    "        # update model without prior\n",
    "        # loss = torch.tensor(\n",
    "        #     [mse_loss + kld_loss * opt.beta + align_loss * opt.weight_align],\n",
    "        #     requires_grad=True,\n",
    "        # )\n",
    "        loss = mse_loss + kld_loss * self.beta + align_loss * self.weight_align + cpc_loss * self.weight_cpc\n",
    "\n",
    "        loss.backward()\n",
    "        #self.update_model_without_prior()\n",
    "        self.update_model()\n",
    "        \n",
    "\n",
    "        self.prior.zero_grad()\n",
    "        self.posterior.zero_grad()\n",
    "        self.frame_predictor.zero_grad()\n",
    "        self.encoder.zero_grad()\n",
    "        self.decoder.zero_grad()\n",
    "        # update model with prior due to loss_on_prior\n",
    "        #self.prior.zero_grad()\n",
    "        # prior_loss = torch.tensor(\n",
    "        #     [kld_loss + cpc_loss * opt.weight_cpc], requires_grad=True\n",
    "        # )\n",
    "        #prior_loss = kld_loss + cpc_loss * self.weight_cpc\n",
    "        #prior_loss.backward()\n",
    "        #self.update_prior()\n",
    "\n",
    "        # mse_loss = torch.tensor(mse_loss)\n",
    "        # kld_loss = torch.tensor(kld_loss)\n",
    "        # cpc_loss = torch.tensor(cpc_loss)\n",
    "        # align_loss = torch.tensor(align_loss)\n",
    "\n",
    "        return (\n",
    "            mse_loss.data.cpu().numpy() / seq_len,\n",
    "            kld_loss.data.cpu().numpy() / seq_len,\n",
    "            cpc_loss.data.cpu().numpy() / seq_len,\n",
    "            align_loss.data.cpu().numpy() / seq_len,\n",
    "        )\n",
    "\n",
    "    def update_prior(self):\n",
    "        self.prior_optimizer.step()\n",
    "\n",
    "    def update_model_without_prior(self):\n",
    "        self.frame_predictor_optimizer.step()\n",
    "        self.posterior_optimizer.step()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "\n",
    "    def update_model(self):\n",
    "        self.frame_predictor_optimizer.step()\n",
    "        self.posterior_optimizer.step()\n",
    "        self.prior_optimizer.step()\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f287cc-b9be-4566-8e61-5f2490f422c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 03:08:45.972070: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-03 03:08:49.074346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13,460 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:25:00.0, compute capability: 8.6\n",
      "2022-05-03 03:08:49.075255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13,460 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:41:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from ganime.data.base import load_dataset\n",
    "train_ds, test_ds, input_shape = load_dataset(\"moving_mnist_vae\", \"../../data\", batch_size=100)# * strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd7d1ff-4561-4b96-a128-960b56f57073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = P2PModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1651440-4888-492c-9fc2-858c61792a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f216418e6d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ed3631-0cb3-4760-99ce-2f918f221135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34024c04a76e49b6ad1511c9f5f972b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdalla/GANime/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([100, 128])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "epoch mse 3.582608070969583\n",
      "epoch kld 24.33021411448717\n",
      "epoch cpc 0.20322215035557753\n",
      "epoch align 25.216130965948096\n",
      "EPOCH 1\n",
      "epoch mse 2.5908395290374737\n",
      "epoch kld 39.14953933954239\n",
      "epoch cpc 0.14576730309054256\n",
      "epoch align 11.182117357850075\n",
      "EPOCH 2\n",
      "epoch mse 2.3822577044367783\n",
      "epoch kld 64.45099029541015\n",
      "epoch cpc 0.1331605749204755\n",
      "epoch align 7.76171635836363\n",
      "EPOCH 3\n",
      "epoch mse 2.2770199179649353\n",
      "epoch kld 86.81971297264099\n",
      "epoch cpc 0.12619281327351925\n",
      "epoch align 6.274997822940354\n",
      "EPOCH 4\n",
      "epoch mse 2.230066674947739\n",
      "epoch kld 96.96366109848024\n",
      "epoch cpc 0.12227157680317764\n",
      "epoch align 5.353533518314361\n",
      "EPOCH 5\n",
      "epoch mse 2.167253895103931\n",
      "epoch kld 96.01606941223146\n",
      "epoch cpc 0.11924541797488929\n",
      "epoch align 4.539233151078223\n",
      "EPOCH 6\n",
      "epoch mse 2.1367987036705007\n",
      "epoch kld 95.5141518592834\n",
      "epoch cpc 0.11690673390403389\n",
      "epoch align 3.987957359105349\n",
      "EPOCH 7\n",
      "epoch mse 2.1204962849617015\n",
      "epoch kld 101.11894369125365\n",
      "epoch cpc 0.11568514769896864\n",
      "epoch align 3.356449429690838\n",
      "EPOCH 8\n",
      "epoch mse 2.0874138295650484\n",
      "epoch kld 98.25139799118045\n",
      "epoch cpc 0.11377543341368436\n",
      "epoch align 2.7833749286830414\n",
      "EPOCH 9\n",
      "epoch mse 2.062134850025176\n",
      "epoch kld 98.29476127624511\n",
      "epoch cpc 0.11206705495715141\n",
      "epoch align 2.3408415369689473\n",
      "EPOCH 10\n",
      "epoch mse 2.036618199944497\n",
      "epoch kld 94.93264045715337\n",
      "epoch cpc 0.11118931043893097\n",
      "epoch align 1.6347623959183695\n",
      "EPOCH 11\n",
      "epoch mse 2.0368886157870296\n",
      "epoch kld 109.22625827789304\n",
      "epoch cpc 0.10982195511460305\n",
      "epoch align 1.1408624663949012\n",
      "EPOCH 12\n",
      "epoch mse 2.0192855700850494\n",
      "epoch kld 120.09001340866091\n",
      "epoch cpc 0.10862862998619677\n",
      "epoch align 0.9572363339364527\n",
      "EPOCH 13\n",
      "epoch mse 2.015162135660648\n",
      "epoch kld 132.25221481323243\n",
      "epoch cpc 0.10813785381615167\n",
      "epoch align 0.879854453727603\n",
      "EPOCH 14\n",
      "epoch mse 2.0168183565139772\n",
      "epoch kld 145.1365865707397\n",
      "epoch cpc 0.10664752796292305\n",
      "epoch align 0.8182895660400389\n",
      "EPOCH 15\n",
      "epoch mse 1.9925226986408229\n",
      "epoch kld 145.33572769165042\n",
      "epoch cpc 0.10602607335895299\n",
      "epoch align 0.7860119879245764\n",
      "EPOCH 16\n",
      "epoch mse 1.9839354828000066\n",
      "epoch kld 155.5431171417237\n",
      "epoch cpc 0.10492418007925154\n",
      "epoch align 0.7639380648732187\n",
      "EPOCH 17\n",
      "epoch mse 1.9927543371915817\n",
      "epoch kld 163.33383970260618\n",
      "epoch cpc 0.10407889503985643\n",
      "epoch align 0.7452600598335268\n",
      "EPOCH 18\n",
      "epoch mse 1.9633001327514643\n",
      "epoch kld 167.77337503433236\n",
      "epoch cpc 0.10263003362342718\n",
      "epoch align 0.7206407342106106\n",
      "EPOCH 19\n",
      "epoch mse 1.9741527810692787\n",
      "epoch kld 176.66469669342035\n",
      "epoch cpc 0.10235550338402391\n",
      "epoch align 0.7229534715414048\n",
      "EPOCH 20\n",
      "epoch mse 1.9507026776671414\n",
      "epoch kld 185.10967884063714\n",
      "epoch cpc 0.1010230141691864\n",
      "epoch align 0.7016348328441385\n",
      "EPOCH 21\n",
      "epoch mse 1.9610734000802041\n",
      "epoch kld 211.38427028656008\n",
      "epoch cpc 0.09951995555311444\n",
      "epoch align 0.6828564260154965\n",
      "EPOCH 22\n",
      "epoch mse 1.951112118363381\n",
      "epoch kld 219.11678180694582\n",
      "epoch cpc 0.09834386520087715\n",
      "epoch align 0.676658158749342\n",
      "EPOCH 23\n",
      "epoch mse 1.9609183698892592\n",
      "epoch kld 225.58344345092763\n",
      "epoch cpc 0.09772481741383678\n",
      "epoch align 0.6745423316955567\n",
      "EPOCH 24\n",
      "epoch mse 1.9504618585109712\n",
      "epoch kld 235.25317440032956\n",
      "epoch cpc 0.09548988230526448\n",
      "epoch align 0.6633596755564212\n",
      "EPOCH 25\n",
      "epoch mse 1.9500137627124787\n",
      "epoch kld 254.67262039184564\n",
      "epoch cpc 0.09396524354815482\n",
      "epoch align 0.6556126199662683\n",
      "EPOCH 26\n",
      "epoch mse 1.9461416170001025\n",
      "epoch kld 264.91344604492184\n",
      "epoch cpc 0.09291161065921182\n",
      "epoch align 0.6495816413313148\n",
      "EPOCH 27\n",
      "epoch mse 1.951327461004258\n",
      "epoch kld 281.74740505218494\n",
      "epoch cpc 0.09079327769577505\n",
      "epoch align 0.6419041965156792\n",
      "EPOCH 28\n",
      "epoch mse 1.9384051606059072\n",
      "epoch kld 285.7681577682496\n",
      "epoch cpc 0.08901036055758593\n",
      "epoch align 0.6374196156859394\n",
      "EPOCH 29\n",
      "epoch mse 1.937698304653168\n",
      "epoch kld 299.0713453292847\n",
      "epoch cpc 0.08742281626909973\n",
      "epoch align 0.625818670168519\n",
      "EPOCH 30\n",
      "epoch mse 1.9443992823362355\n",
      "epoch kld 298.8507230758668\n",
      "epoch cpc 0.08511219108477236\n",
      "epoch align 0.6250018566846847\n",
      "EPOCH 31\n",
      "epoch mse 1.9605368688702585\n",
      "epoch kld 319.83222808837894\n",
      "epoch cpc 0.08289596540853382\n",
      "epoch align 0.6168163213878871\n",
      "EPOCH 32\n",
      "epoch mse 1.9564562022686007\n",
      "epoch kld 326.5262899398804\n",
      "epoch cpc 0.08080559456720948\n",
      "epoch align 0.6139197111129759\n",
      "EPOCH 33\n",
      "epoch mse 1.9322208598256114\n",
      "epoch kld 329.07440605163583\n",
      "epoch cpc 0.07850348390638826\n",
      "epoch align 0.5914536613970998\n",
      "EPOCH 34\n",
      "epoch mse 1.937739443778993\n",
      "epoch kld 337.4430347442627\n",
      "epoch cpc 0.07571170106530188\n",
      "epoch align 0.5976562429219485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m cp_ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m cp_ix \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m mse, kld, cpc, align \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_ix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_ix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m epoch_mse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mse\n\u001b[1;32m     19\u001b[0m epoch_kld \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m kld\n",
      "File \u001b[0;32m~/GANime/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1129\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1128\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mP2PModel.forward\u001b[0;34m(self, x, start_ix, cp_ix)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# update model without prior\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# loss = torch.tensor(\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m#     [mse_loss + kld_loss * opt.beta + align_loss * opt.weight_align],\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m#     requires_grad=True,\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    356\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss \u001b[38;5;241m+\u001b[39m kld_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m+\u001b[39m align_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_align \u001b[38;5;241m+\u001b[39m cpc_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_cpc\n\u001b[0;32m--> 358\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m#self.update_model_without_prior()\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_model()\n",
      "File \u001b[0;32m~/GANime/venv/lib/python3.8/site-packages/torch/_tensor.py:399\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    392\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    393\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    398\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 399\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GANime/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterator = train_ds.as_numpy_iterator()\n",
    "for epoch in tqdm(range(200)):\n",
    "    epoch_mse = 0\n",
    "    epoch_kld = 0\n",
    "    epoch_align = 0\n",
    "    epoch_cpc = 0\n",
    "\n",
    "    for x in train_ds.as_numpy_iterator():\n",
    "        x = np.moveaxis(x[0], 0, 1)\n",
    "        x = np.moveaxis(x, -1, 2)\n",
    "        x = torch.tensor(x).to(device)\n",
    "        \n",
    "        start_ix = 0\n",
    "        cp_ix = -1\n",
    "        cp_ix = x.shape[1] - 1\n",
    "\n",
    "        mse, kld, cpc, align = model(x, start_ix, cp_ix)\n",
    "        epoch_mse += mse\n",
    "        epoch_kld += kld\n",
    "        epoch_cpc += cpc\n",
    "        epoch_align += align\n",
    "    print(\"EPOCH\", epoch)\n",
    "    print(\"epoch mse\", epoch_mse)\n",
    "    print(\"epoch kld\", epoch_kld)\n",
    "    print(\"epoch cpc\", epoch_cpc)\n",
    "    print(\"epoch align\", epoch_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db1eea0-399f-424e-a468-2058793920da",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = model.p2p_generate(x, 20, 19)\n",
    "generated = torch.stack(generated, axis=1).cpu()\n",
    "generated = torch.moveaxis(generated, 2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd63b63e-34c7-4be5-b80a-f28ae2566995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAASPxtZGF0AAACrgYF//+q\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzA5NCBiZmM4N2I3IC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMiAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTkg\n",
       "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
       "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
       "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
       "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3Jl\n",
       "ZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAu\n",
       "NjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAR\n",
       "PWWIhAAR//73iB8yy2n5OtdyEeetLq0fUO5GcV6kvf4gAAADABacmUP7YcdOWsNAAEKAAIWL095/\n",
       "/D/EAVnBQs3vPUN1p2l4kJUWBgW+TdTDj4CNkhdsAkq0H8HiPMp7Mi/h8yIxTEj5lKlTs7+RWqFG\n",
       "Z0zK/t6TMUcYhXJb7PG0DXyOhcqs8/nvxiyPnLsYqEEQz+dQ8g/xqNYGbXBfsJts/75J/7p0C8qV\n",
       "skirv9YOEc/U/+QLaj0wWNXgKQb2Hx/5yxJiN4C+39+M9Jlj9FanYSG7guMvnZmjNN7PD2vG00H1\n",
       "D6dMclKpFqIdR0iqqti4BmVH4XECtOOxdTf5VRdBzXQhnLQk+D1+0Nlb+2c0ZhtDLW++zRQN+zEQ\n",
       "ReLt6TF//KmT18i4g7A9RmJa+Trw/JxaNeH+xuDM5+z3R1OKkGAuAsDQI9dg4Wx2ietkLcIM0tOq\n",
       "u60hGOkuCGtEkx+5WX/vlBkCc7PNk7+MYdgMFFUlbfIauDoi40zjj1m8mH50A1j6NolxmjpDi+fY\n",
       "+4pHZdxfhrPen7EO4TE13zYjCkzvoQ2G3sZf7bt9nkn7adkUf1k9zdW/PG2fgOiUQ8xveKPv56+D\n",
       "lGCh1ib9JQc0dUYBDKa1jpBHpeYB4PXDByhJg2soWmDT4uchT+u2bNY0xuEotaz91aiKmUXKXuQq\n",
       "1OYzpUSJNH13w2rG0te4pal2XkcfB79hW0EnjlU4orW77mDz4BKba1Ne7+d6slvM8fAIgDw0rZf7\n",
       "mbJ+B27zF+SIQh0AqjK7mCPrPTySxnZNhbHmb09Wl1r7nbZ00WHOc/yDCIay1Q1/E3p5zY4gwEF/\n",
       "t/BV/6aZhg/+drz7dJ0I0xQeTIuJETXvvdXSWxYEMP86JlzgOY3lojaiPrbcQLjwCwvwYKNh/GfP\n",
       "BosbPx+RkVK6tOjPx6JgLvZ6noLC+Jd0JrA0sQAxS/gwXPf3CL9vX8BeAp8yBfmxN6c/YwXF/7WF\n",
       "dnXwNWJXyUOyeBsYPjG6uoCUbVuOGQAcbBw0pKD72CnNX/UJR6vjTYH5SnlMS8OsW5k87frrEXeT\n",
       "lYhumsKxYwdtzFMYwXSSy+7uOzmJmk9MiLJ+YqVMVqQzaq9QlCMsraOT8+z3gaqrzuB2VzxOaqQd\n",
       "9kv/sEXdk16R9mFm304ZMIgz/GdjFzsmF9Bwlb2uc+u8xZYVLFWbYMRbaAk3pcYm/549rO1uYYZg\n",
       "iW0wJ0IczbiLxzvlvR8IWLjBa8CXXsNG3/Z0wP0egNLJyYhpb36GXfxbAA6IDcBHXqh2fitR4u/g\n",
       "lJziS6KetfroxuJ1j5GNVVY3hXDqYzUKAh4zQfMA3Wbm6J3S6SDmRMPHElYXaQHNa5RxZHqiC1gt\n",
       "IaJRcL95qJHi3RRabW7AQc6dI5BxdNZhgkK0rPJzK1A7Wn77i5n7hnoTng5SVcqvc7A3+D5GCHdb\n",
       "KIiBWUF1mh6ARWFXVKH54bbkalI2UWwyubQe/UhSGbNUmXQqXG5CkPpCMapBQJpEj3liJGlbRihd\n",
       "90l+4BWUBj2tPas8IyZbIbjfMVSXZCPFbypNVpHCwPPn6vQMlVe/6rlEg/e8WVtyCru2/wdJf6qs\n",
       "tJwFZQad3ywYSUwHbbIGjANVsTUpPamiZZVyTotcWWMX25A0Wc0RAT2a77sN+bfeh1iTYv6gMcRl\n",
       "ulANu+DAA1iPSilGabAenU5aypxUihFDlNkWfo2vaSAAaQIyPhGIVG/dOS6T7t7eRiYGls/mXydl\n",
       "KJVgrra2eKdJIMkF/74ayB+55AVGf8HHL/JQzDRTuFjQC4KC6udIvYJkpE+ELGtSNHoQqw0l1zKi\n",
       "4VBn9IkyYBQ0SbJTp4mwVY1Co777VfKEQVus0cEPIUEw68Igz/GTzUaPb8jhHzPq1SK7kYZUaIyl\n",
       "BN+BqlVk4wyA9vkqyj5sWKgazEQH4pYyBDqwsxfzYObCB8TFY9YQIsI6fWgWQHj6//2/RNX634WF\n",
       "ABkc6hX+uTlN4gq4lGYLVH5nxFUUvEiaiaqdmBkMnZp5+afYIJNkQpDl+7aDsCzwg3EWGB6GqjJC\n",
       "32u4FAx0bXNdYBHxjj3OItv60xOcI01irI0Ty1Qs1xQjdg55zGep2UmhEuJfdHITP5y/oazcoSKv\n",
       "vY9mJBkZBqqXHOC1VmItFi+nQ3XZoPpMIluUClPv4zfSjXkz1Yf97f32ZXT0wJxZwgttwMfvO1q1\n",
       "qlJl1kvh6P8iUNCPZA/1hS5Uwzm/Y4XHbDOqatDDieQhVGfdJqOkWchci41+UHHsRO4afvFSJTrR\n",
       "haa12KO9auOqEkTnmez1ozCVWY56VirlZZr/LHNujWoKR9+O5xOKouvFRDxChM1GIMnfq8rrI5Fe\n",
       "UY6+PwAz7tbuGG8sMLhCmh4VxSBbiPWBH5+DFF7mW+345MHJx+HksdefaSn4PuWR6KKS5AtY/OPd\n",
       "mAuDozD/ZBToiKEoHpl7ly2zar6T5I+YW9sUiOkv/KQ4UjT/5HFQtzfq2HBNfS89/y35kxT4b+UP\n",
       "aCZW3OlVJGsjQP9DVnvLlP/oCZA7nYrQqqG4ZON1Vze6cJdufwAEVagnh5wrVnUNVmcS8h+PM41o\n",
       "2luuQue3K1t0EYdSVsZsx/opjXTA4gcsEsQh3N9Zd80KrZO4B1vpL/6SpgzUA690QI7owgWF4nPd\n",
       "bK7BZkNHX5bU96dbprqLfSXPUryB97j0SqHrB7CCZKE3f8Tsy7PJA3KeBUBQ8FawAE/DyrHzJzho\n",
       "bfT4nx11+SLXSTBcPFqBAOA1yNbG9uj+ztMkwerYU0can2PWYGjt+/6nEFWYmesT/mwI88/AyfpO\n",
       "JT54r10BlPy9OxMrn3u80637mVKSj7y2JmjPi4hbELOeMu+12E4TfrxnkggxRkDv5tKm/2QDDeU5\n",
       "blqdj2lNQjU1keclfqQWkSH0JSG7yP2xiLMqTgG4gO0VETl4aZUM1SZNd9dnaXo9F/D2pYGFpJV4\n",
       "pUwA4I/5raFo4tNWo9dRuJautzKO5VLvs4SmAXWemb6VAxki/G0WmDz2AbCns2N1gighpP99b3a2\n",
       "yrknKC5rKewbYoC8C9xs9WDLKwcAdiwOuX0SYw7SsUjNje6cFnmp/xdoKKBPrC1WAPj9lnhYvCV9\n",
       "jrgWk2n5GtiuzHv9SLdjJL17G/VqZff8lIS510EZkMpWaMNR4k8hL2mg1OmDXsTN2BdArU5InwQB\n",
       "wCBfkwDcLBt7GCNsED12GZrJF8yNU8Bis2FXzdDCz5HNx4Ein5Z0Rm1D59OqB3PkuiYewmYaKuYL\n",
       "yjEXpT58dKoDugpWXQHJyy4XK7WfXz5JLK2CbkV4dZGMz7d0jSUh2DzTIPdyuc+ThilqL4R9AZds\n",
       "DmWOe8Cb6EEG79j/guhMjoqsR4PlavY9MgvcEpCPtdkDCj6hgUF5vhyfg/ve66SCSfwUYCD4zEbh\n",
       "K0yXR6LgXfL4xgDjFpDxauh9FDGuipjunHOYtlrYcORwiUjHxKgCT4H17BQMSbXobbPJQKKY3QK/\n",
       "+3VSbTfm3OWOArQCzkhdl9pz8y6g559+4I2/HgSoCP7rzrRsuDhnzF7nF/cF2ure0+IsPybClgHV\n",
       "1HxH6yXhikZavNFv5xYPCZwDPD7s0jmBB6dTqhM5mHZr4M9IQWqIL917eDj27Ld0f5hUFqA/3lcN\n",
       "eBKngl1+nm1+RXOi+I42cp7+7yDe6iqFp1PKsvJM5pmR4RAR4ZiKj0L0GE5TsjFRgvmXEbKlQZTG\n",
       "EH3isp4bQZ64IeXjoRmPszuduJncz8C7QLnx7S8pzMraTFfqjE0kq1BMa/kkRKxDHz9+Yil9t+6C\n",
       "WEN2wNcL819hR+mhn+usT43/7CMSZnVJ863fkOerS7TZkst8i88tOopsZt6L3iFfRa3iGF1Vs/BM\n",
       "+1J2GMv2G5EyO7ocym9gNtFZ/mE4d1i7QpwI+e3eH9t8kb7//E0i7/JYXAn2XJnfBLKMD++3SWDm\n",
       "lzq/GUqZ//BA/wdymV27yEEhdBNdnvUzbx+hv4rBLCijck/N6w6PrSICqcslGQ/SvlflEiXKOWlH\n",
       "eedn1z1aF6Ms1uJNZFaekQMKPzdNe6uVf35ZDUBJoF32tU45ZHgy+0kH92WWYbH7BJnHORQQ9NSk\n",
       "43HgvRtoyfeQQ+bZFgv9Ehfc75v085ecNR1egkO0xNJaC3ymB+XoP8QAWjMAgfazx+yXgiou6BE0\n",
       "GMkKRtu5Y5DqVWuEIn4r1eFX3sXqVG+LaJdSil5qeaY16izEVXBVKu4KmyHiNBVlItvOyZYbdNcq\n",
       "Cqd9+kRgYbUq3SqsSLVLx03oPcv13y7sgP861S2RbxhSKmRtOvhUhQpYVB5JcCGx6XZ4L+7aHjSW\n",
       "/36v9s5waG917zfhC0SpskcscyCqglqc6acGNV3ZxV78/fChhGbVbDTzjcRpFJv97EprL+/8+rvl\n",
       "QwgMeyfrTjuGe89MYGJQ3rxwgH/bROYwrGQ2VgWDP+7qZmTSVRNjWgwHfCjYHT++7Zc2sVlAWYL8\n",
       "D0jetwJ2+sz0w2b1EI0P61ObA/OSd+FbHN/uAwv+et4siIAfeT23qacJnq6GE5SAj0VksGLrjEIm\n",
       "SO2Vzw2l91aq4Xrym9BgKfTEYeFvdiVas9LfL1Yt5+nkrsPOl/xjnUrMSZdKBumBztkpF9zykUiN\n",
       "5NDGlgcP2S6fRQw/ytgJ4TQTogRhK6f334mfnVsiQwTSk4xecixE1U/4LF0Ywyb0VZG7L7AHrvcy\n",
       "a9a9yeyCuaZkFAqeqyC3lUrHCUB4X06//hq2lhnyYfhnOkKm+Dd7yzCD47O8mEy5CcLqRPq0N4La\n",
       "4s2Iri1uwDSefzdkpr/NhBbpz9Wz6px+HylmgiLc0VZRN7/svLxThpIJqrd6GRb8zD/lmmFbJzS3\n",
       "teHdOukjm0DCSKc2g4E9P8sdAcBBucCw4BqLF/VPFmBXyjgWZC7jQAM0ep8xL64kSqg4Wi+Y9TiI\n",
       "IY0ou0xuwUd5Kp9JLbR1wil6+LZ+44UDplFJh2g+Fklyf7v9x0BCCiADOfANuCiF6qzwaBkSdzFN\n",
       "JXYObE1iQnKyEO2tA0X40HoE/NH+TomHPZZ8yyTh99+sXJ4HT8wSw4jk0xJgXhNitQZwN6MdXsRf\n",
       "saWLcTf/h5dyueoUSLRX4iexMwTWk68QrjP+4TfqP5ldZQjmznz2ld4ynP4gh7czSSMTqwAQu5d4\n",
       "89C/s5OP/SDgwfTPGNzrMSM3/zkf2ZpD5f6PtmTu9IZELlnelj5qNpFYorKts08YBNct5bUKC0L1\n",
       "MCsASpRnGD1v8jzp4VF7aYXtjuARdQs34Iz4vsEVRBRj2u71+fzuhIU3Kmg9tcqoWNnT5rGzJaMB\n",
       "FktCBelfouJ9RYhliAKTcHpfUgdS216bG+0PBWSDYr4/RjpIpubm/zStSgv5lDYzGDv+KxPavjdQ\n",
       "vsumXNQxbNk/+EcidYAxXGLAksEIq0vrhone05GQN6PoKHr0Coh5wukvNIgczem5dB9ztrja+QTd\n",
       "qGEI36KG4e5O94Qvc/BdT7++DRD4VFB6x0CapM5wxA6TKBxFVHzjn5OzqeSg8VcBsHF5fgiPpa3Q\n",
       "gizgE0lamhYdiEtFwfwQ3xs3mQKGDsXbdkcZO8htk0T2BMLl97r0luJiK4hsaR3Yp7glq21NeCSk\n",
       "vWo6PWsO2mTVWOfgMBg4hR9gaKxBFc0lbqDmAl5Q3n56BOuGO3vaUF/cAbQjpQjJr16QTHLT9Jk0\n",
       "xezs91I/2FTMBOOegquPhZRgVmCG6fRAZ8j/v3rMvR5ujNmcBfD42YqP7mkPFfaarNIbXwOt1oXO\n",
       "3zyC95+1acLOL4Yad0V8nizSYV5cZOHq9gB8IEGaHn3dlLwJfVSTMMLb608mXVs46CrWsIO5fmTD\n",
       "w9Xq8pNFXCn9b2ZLMQpZFAAAAwAAAwATUQAABNxBmiRsQR/+tSqAAdJycIAKcBi4uKn6Boplh8PT\n",
       "I8m+4sW372vUa4eiPn7j51KmE/Naoy1r+9/pTxXU2S7v2TuJM5roAadaADpjsqEhLvRfqOxGP+ps\n",
       "m1kXl33j7AYyPcQ1Tjto9hwP9+r3lKkiQ9etoM3iLrx8oph1LvXMnkXyPZiA0YkQIYaGiO3T45A2\n",
       "bNtQUCdPdaOHkJMK0p8uU8RAPNuFSI6wspLJBpZmy0dWIObi3LhYSLZJL2zPygW4E8AS3bvq4UnR\n",
       "M/D5Pi66V1NtD82UWV7iZKOiiDLddXT9IOD46yYGgzuasAJ4W5NbMfCcsmw+/YmK5TrKuKtEVkTO\n",
       "LiM/Ds1nbdbZ77aRyslehCpD/L4ZdHiXnSlvqdLv61q7eqRm+qVY7V33JNPkgqkYMHXDR/Jusvcg\n",
       "vW8+y2W0GDkfe+utkKRao16MDuy6Doc0VnyPM5f+LlsNwvWYyiiEzZJ2C/aL5fDkqfkdK7D3zdHq\n",
       "1yoEj1f39ZY0nqJQBrWf9F4uMDl6YWIoI7PUcMeOKTd+qoYImBtD5h86YOKaH1Tm8f0OwG7RN59D\n",
       "WUXEYyhYV0y9d/ej9/vRody8/01MrM5pmEXveLDWohsQekFa+ZUUN1Pnc/i39ny20eOE+JlFXKbU\n",
       "76vEr0/bKmZtIrQs/xrnmDjN9HtakHBcWMeBrbzkCmKPrOI/XtORcX13OzuPoDGDdDhXTXpVBz8U\n",
       "Ru41wxPwfeammRMfpldHmNWU7ixU8cLJSnGe43TwFK02aRg3RYNW7+JgiwkI/vh6BknhcoR87u97\n",
       "YvQ4pRcA98DO4ixEK3nLikzXS34wOBQ2pw3m0Jz5Uu9uSpORL9lLqF1ns8XVChByKut6ziOMyOep\n",
       "6aA6NmEmFM6/ApM4Pi/hWI8He5mIw6HwKFirYYycPLIq2Bvus+oui/21HT4UHatyrMs7nsmkRsN/\n",
       "ksXzaY2cZjgepuRrc+ptWRvjKGS4117fYu6PxRgJTxnDWwN9bCmCoY5zV9xN7p1pQTm+v4V9ILFS\n",
       "Q2FZsggTgT/TmFH0f/Gdc3S6kZEitLe7grRgUr8ZP/PlJKOMfsklUu9B1Ch8QrSD/gCeeGAxB8tj\n",
       "VL0OnTCrN1z8i8knk3lSQF6Z1G9usVNBbyZX3+7VYZ5PK65YmPnbl/D7m/aHTw/NNyRl1I72gWz2\n",
       "RX32OPHwBbWukq24nC/jNoyKBiv76cQZsUNd14x5OecexCow1nncREwIdGkt0ID6UFnnq/EmUwR1\n",
       "6aLzfAzsfIZq1fEYx5whPj1nauH//iNzhsmqM9Vuu4SNhr7/95A80INdynRqAW30Ogk+DkZtYHPy\n",
       "a6oWUrdYRlHlGEVooIOR+Pj5WG73zeTvXS1IMs3iaYnVnCW3LG5uGE2UdXzXh689wk10yTZsswaX\n",
       "ww7Y6jKc6SbJ9sXIBzS9esdxlzacshPKbeoKEQV7KCvY0OHDE6LpsNY0M17fkBAID6q2r/wadW8p\n",
       "UihGihQblVKpZ+CDjDlZcFgJIgmX7lzjw5f5oBEzOCf9c7v6P7XmpfAx2g26QUcghCKylvJECToC\n",
       "0LXIcGhJRYmxJUjeRh0YNuiqK05Vsr/V2+ofz/48LZEjArn2mT6Ni+gO4GRtxf9PY8tRaXHqv04I\n",
       "F3VbTlEUDdkNl0QcQkaJXjBvQAAAA5ZBnkJ4h38ABx9DoH7tdwBytihmFJAqvQLL2Al63qeMh2Eu\n",
       "D5mgffOwbRnf0hGRnJycx1tqhLwFYViQquolOceyI0B2BTRCTNRaF0Xa98IPvRT930cjeSbu26Sq\n",
       "FZ+wbH6jO8Eyd9LJiqHfOYcnkcTpXvDbdXteWPkR8Mf80i/NiDknW6Xn/cZqbI3Wr6UX+FFItY5P\n",
       "/5EVWMhxWkrWu4wKwXbQX+MqJe2OJZZTLgJsArIhrd4r8ncVAuSzFEfGiR3BHsCRi4YChHN9nQXo\n",
       "c/zaMPqnuvEukLfou71P6XGgIW031p9toci8Swhu35aadsVPay5Ys3ZgT0IJu6tlmBHIXmo2v6HM\n",
       "KSbC2nI/fTZSrpEpAC3ZzXTXc0dTi9esrKvAk5Dbk2rbSRJgSJo6pemKSR1u+FVOOENsmW4Alc/+\n",
       "+UJXHi5zlZ6RVQ5mMfEugCbcNVlZa4K6DjnxPIv2HZIAjIBQK9pAZwrcERWgELrVf+lE4DpSKJ/B\n",
       "3MrgTFx/SLOgUd4ca9j4BNt4IclWZVV38DMBtXwD6whn0MYkvjHO2SdAAUFC9Gnxn4BlsSUUhl5C\n",
       "s5IUAziHjOz7dwlE9aQ7ruOl1zNifHRP05vQRbqBnG0MEFm7WxbV2fQyYL+FdrPl78SSL7mVvDqB\n",
       "EjI0mdpzGP3ohHRsaLQw2og/JJHWPZKnX2sU4eChqH2uV/McI0ORCuPbFqjnNSm1lZKFHDsvBrMT\n",
       "Pt/sk1V3umC2XCZwpufq2fEcGcSN9QqC1FA9qfdRFTMr6l2SoXtVo30wo2EtaZ4b4FNv+4OjcjDF\n",
       "MvNp/DIpqmrAXrwiDs/7cFRj6Ef6hB0ZD0FsWR4iRVBodb3Iq3zROI2pjlx2duZTVhqp+Myzxuw1\n",
       "CF7C/ET33ebMm+FseRdRHik91BAjJTclXlLboBNaYd6W1WmPoWgxKfuQKrk5XbnlsCUg967/n5/G\n",
       "7YbMBDAKzD8Qty2eJNuXElB3yFCGrxTPyHxuwHjEiqqnlAa/VwowZfWOMecyg4RTo4NMjneYjNI/\n",
       "0mzgawFNvaurk62L9RhYAdftVHzan9GRJVvWQKZssumEfs3N3apHEJorqWP1g7l4jHdSWKGgmmAH\n",
       "0arM0/afg852FTMs6cvxVI0o66veWDf6lZlAISwloEWe14HAxF3ue8xeBVr4Cz05Ur0UHqXdQIOt\n",
       "37oiQZIgLjVp7WO8jwefjRltW6QsB3Hjv1Mj4XcAAAKbAZ5hdEN/AAo54QO63UHLFYJF51/UE3PA\n",
       "bPteacKckPexNd+bn9IA3P+7YV4C0eKxpImKZqbbROqdKd8gsiQ1dEx0sSerl8OuCccYcn4ca6Sy\n",
       "b+CIlmVmVERPwBFowb+1p6WsGN61xHL1DsZ3iimE5Y+sNAOqQPpLFrRbhqsAYUsRlRBh+uEiHnw3\n",
       "tkL1p/i8hUNRtyPpLyMGBjlS/D5NODWfpHrjyOvmDYeZ597bDs2QjSPlTepZ8R6JzvqvcZOZZXYx\n",
       "QU1gLayxIYNRP/UC1CVJ9J8ngr9XyEGUgcrG9AD5df0eAUD08iSeqj6fN3ocyfbixHI933PFxBLc\n",
       "m0blEEUCISRa4vgH0wZMlEE1HocMGN1MxqWXC2cyGlP4DRSf+fzAYlkRm2H2YdRbiqsQ7DWMjY2E\n",
       "ZL5t2JF4o2DU8uwOGFl4GthqTr+oihGq5SHAOhwz18Zo0rVBkyrnGxUy80pjEf5474PTUvaq0ox9\n",
       "D+dGLlFimjcYD0MObQqL4ppv0JnQpkYc4skmwmHxxnjkLr9NVtRiQ/JmeaPRHwyMyUmkaVMD3f2s\n",
       "KAQIlAxi1dLg7W/3tkRe2z1NShK0v29IEYFfY3tqCAKkH4xErRatUBT28pT6/ZDHnFOWHbWq+OJT\n",
       "RYsaV60BbO80qAD323gWUYMpuaQuW73app4V7lrKavjM59EhbTwnLEJDIe4Xp0i8QOQ2JG18+bZL\n",
       "H4ppbnlY9L2EwSf7j3pFe/ySwT/AFj7TuoGFSZKK6OZUZCgoTfZsV3PUTrKhZUQPYmARP7S7u9Ry\n",
       "DIXZcllKzOlnvC19W9RKPFW6IRuIBSgPgyYVgGbjl3HK77h3mROyVNXVz3gx6v0Iq3cc9OCqw6pY\n",
       "5cDWMram4NzN4XHHNdYtoAAAAY8BnmNqQ38ACY00caGfmgBXO3SRoZ8FFJ2ApU+88jGHRWF0p/Ly\n",
       "AZnUSWhr+7GExcwa+ygjSKg92YDa7a+hIWZN2qhvGDxtK82/q1GPeXecxlhW6Y1HKf/cl10PHKIt\n",
       "Vp3POeGpWWE1AYpD+DTUJo+TA70Z17LaiqhbjPk8YHN3r92WSX8CrOzix5AVIGTenq4w8UFC1jKX\n",
       "jFI5dvGhDBSE7eL9IwZNYBYQ9p63kvpKvoUsjr2iFMC5w3URWnmA3tuP6wDZhcTYGtvTpL+oXTKE\n",
       "XuZcDEfIs7f2kyy49vu2+cKWXyce0GrYLCMObVBHWt13B+5GQAGDDjpWVCH4AGTYQAotDXtGmJcW\n",
       "seji5ivYENBe6gIkGWEsa9dckGsIC7EjZn7h8Q315rdH3bpYCiGsqSkkFbqquvpbzEXbxOm81SDN\n",
       "xtVITUwme5HaAv5GzfmWxlLpit0jL7SLLkoLq5WYCHJRheKVCeAzBtzO2shTIVAE+lmzCBwaJC6n\n",
       "59xPb/skviQpC2rqDz1+djZW0g8AAAOiQZpoSahBaJlMCCP//rUqgAG8pJcdxol9WAAesEFKvvMn\n",
       "DD7LHZuX7Wcl+6u1/ndLMQsRa+Clx04h4L185xfVkSxViJcwsU/E0uE/wpAIzyntpzBcrcALlDj1\n",
       "PD70DzXBsvjBzL629fGr4gYm6+z2de8EaTU9jebBSKe/pGo9CG6LMBlikA6UeEk+VdTBsKfFdp6O\n",
       "RPit/l8wK18fSx2zIvU06sloUcvb45477M7AIfSDLOctiZmd9bQEh6D7y8w+O2fsS99FTpRHuOn5\n",
       "4f8940ONk3xIONkWAa2QuniA6KJMHhsQL8in3ThDh1osDOOZDGL1055zCl/liAoxn343/0JV1Ts/\n",
       "6bdwb+XURNbniQT98iDW+bpdM8RDy3DDKOQDT7LVZCMFYR7e6ND0/xybOL5JjdY7Xna43o1sJgih\n",
       "64ziWqdI/w+p2PYMxJ9tcBNagdNhHoekvpGFZhexVjxeZE91rNvFqeTstWk7P7i9z4iE8HNP2aM0\n",
       "OpbYXEDRrxLz6XBOA9akiTb0bhZQ+f4Lrr69Cm9uDx+sLSXZl5aNXVB1MGoj6kkp/Zj3NZWfhiSH\n",
       "YxthBJ181QsgbWJkZBB0Y6Ge5RM61FbR7kAvZetvTubTVbEZH+7bELc9k+nTbCOJNkm332h7pu3i\n",
       "uxVsJbX9mJlHXb0VxjrrfGdZXf/m4MG6mSAKSSy/T5HaMISWnQ97WjgvG0q+CzfYPiff2lb+7/wK\n",
       "Jb+Y5JAE3J+cMr8+dD5WFTsy9S5+1d8G9ogtD1sYwmDHvBeLkolrPUF3DYs/i7lpKGyQ9xCrynkM\n",
       "gYxZSiE2Ix3gQCVE8GHjxrLBbOLIfFxbpQ+1x4bhOFgHUw2A+SvNNOMHefwsR20Q2+Az3tQDZ7U5\n",
       "leHj+/nFrY0Pjzy3LWhy6DQutl3aoeJRy/ut/mShDxUgg0ZHa+y5x+C9uy8b3+cyhzYkAojxu0AH\n",
       "cNurCAe9tIa828Z9uHnWz/3FuuHoxfgw174hXsRHoHxNe/ZDalIuBFKQmRs6Av/WVzN5ks7BGv7O\n",
       "FElbW6nW2dvLJ7qUrLDpT/z8DsB4iVqUU5aFJebJByFW/BfMPgoWl1VEo4ccd9K/BCQ6C3H1UKGH\n",
       "qGlzMsOyVjgoLXQPSqEenoxS/UCden6DuaUdBwCMzIu8Yy2/UDKIqzUO/fKpLbVlsAi1Dtiw/SpP\n",
       "KrQ9LGS+aZzuToMasxL5XpsQc5HxvysnK8Wkg8r3rPUS7PJyrHjfRsFxAAACuUGehkURLDv/AAa4\n",
       "Ttv97YD92LK0auZ+kfbos1piwJ5hyt+d4UGtXoGClAxD+T7ejgO5btOpKFnZCZ7mzlQJUujkKtsS\n",
       "Kfv+FN25K6TrrpPOPieMwagDXqj2yuU+6e4hSlUospThIdGOclz7JqyAxPhpjcv0zlszOoGGWxGa\n",
       "B3yTE5DUYCcSksBJeyGC629mz82TOpNi7jd2dX4Aj6pyC3JLD1zGJXOYXexCV38fwyU+Mvmf10k3\n",
       "dAfulvkDzvuhWnVNMoMwlOAcZv/Gj8eiwo3DUgOeU9KJhWZlCD4PTudrsoi6/XdaouVTbRBhd6/l\n",
       "pMZOWc0B0cU8+LwF0K/lJqXHEJ6+yYEo6aFEXkjRdaxlLQk8Aw2uMYgnVslWC8sxwdXy2ZzcKKWI\n",
       "vrCnww/UcsBYeswGLBNJVz6GjWJU7XmNBfRITxUQeXaWRiDQznKJegyD/GXOMrksGnmHs8SKI6Y1\n",
       "3dvVd9/TjgQKYFkVYfv7RRd7+3k5CSmcvN1j5uUhVsR3zH9HPnZJMYRihnuxg8+GMDhJO5PqXsBB\n",
       "t4dW1OhpvxdPewygrX2tpBasKRUI8mVMDpfNNGjAL8Rk+shNXdaKaTH0JqJgGf9DypNQvDCOnGJU\n",
       "PD8gI60wzIDj/QBex38KnOmx+Rd8RKQ+9f3vHCunLEBUXYHYIyHotUH/EXPfiuUYq1yUmIKN+V+p\n",
       "Jk3fB99jMYwdsnG4i/6oeLs22oo63hT8rLdj+AR/xIKi04EMZS9nwO6AunGqlSl1x6xNK3SyJ3sj\n",
       "xq4j0l806MEohklNZJ/1cyf/+9yNGDgr+/x6DInAkcJLsY9kryuPR+EyolIFtFEzDRDN9KxX+wT/\n",
       "q50PFJzlq9Bzaq5v6Kqj8k1QqE6lMFXIceCDg7ZhZylXCw9AvQHxQFDxlz/ogSUAKfrpOSq8zgf4\n",
       "P8EAAAFzAZ6ldEN/AAmhUdZ0A6Zk2gBXPV6RCzAHbuQ8beIUvzuaxXrhWUO7vZcPaSObq9GQVcV6\n",
       "INfAHzpvkt3YB0yBunzuvzaNxeVWYFVBMEhk4aaqW+Bbkv0YEqGMJLJxCHLe4BkpfiQvpHsyqgSS\n",
       "BdyHEXHAXHMFYDOhP1FLwgRkY+XXDPJEIghJw/bgINgSBvi1IJrsa6HP7c1h5sfXMTJbzX0NA4lY\n",
       "Ubk621ddFEP5Lmrubgmx4WWKEFAF8XeIf5wIq54W5mdvZlGqZLdqb+zVlbJZZwj4zRr2ZoGm4cqe\n",
       "UqRnGhIuLF/rLzwAoOkL23LwDLhtJMjKYElLOMFhozTjcUO0W84WaBkLuR0EGf6EXrRF+0B920yP\n",
       "KysT5KdrgpuCaFYrfweqhYl0NzcrZ9xgIM24ItXUTLPJmXoRxGFLt1jh3+2Yh91HME9+eQXIoGr5\n",
       "VaCL5SJ+5HlK3AqO9m3b3dTBw9pfCtzhj7H+WKbEOthQpIEAAAHZAZ6nakN/AAlsaNOEQH7EIWF6\n",
       "vQa9YUz1Pzeb12zHi5z419BoTYqsukYHvUy1T+HRteqlXURJbi/hTOJGdI2hcobggYhx4GXgStJu\n",
       "RxwJWWePZ+ZiCsCfy/8r+3Njd/DNZP4btMSsyhjCR/XJb/vyNHDoVXnTYCn4Vy9IW5Wpy+OkEGGt\n",
       "IKL2PCHqJtRQL39LofgZC4ZQQhcWpAe9/IJbKmgs7to4rI0P0gp8vM0Jc7JatSFt1pmDJhAfHK4B\n",
       "XzStV4NL8gyUYcywbtSdBG9veMS4brrnOBbpgjjLwVbrHKFFxnOhu23eeB08G2nMsdi66tkpwSan\n",
       "OEbO0djfdtKRsv6OxtK3Qyc9YltEwsNhgvaLyc6z3tESZv2Ms9nzjrjaPk6zOsRCDXHd135QIRpK\n",
       "mBYArDzfkLGfU2s/y4E2nvZdw23a+gYfJocznARwM+2kTIR09lnHGzfgdQtN6vDq5k7rv1jpCl4T\n",
       "01sFNQm/so6uul9inOpVtYH4JBCEN+8TQ7mtT29P3lK/N+OE3dj/IM3+qTLvEl+Vi6zfx1Eb/QLy\n",
       "huIxyLmhfkpiSvyUqyt6agGhlDoBYj/UcPNYEc+AZ2Vrkx5Bir5WxVlfgsW7DbbeoHaubN/wh4AA\n",
       "AARCQZqsSahBbJlMCCH//qpVAAN5PnYjq8J1z20vmEqWrTjSNZaCmmDr3Z4oSYVH+5bI17eNqVUZ\n",
       "pg2zeGoY6CMTbyJrkbtkzww0warAonouuWlpnWFn/fOttvqqpmsq4pLkLDGVtZHVO+bTTAbv3Z7R\n",
       "dPJzyf1OD98z2bbcugsa8mPWrFPyBDNFh/ffdHY7zxix+3z5eKGC+Kh6l1a1uYmU0inmgyYD0uOq\n",
       "nAh6xe85jhn52WgEWckeEn2EoO44WNLgnBXSC2zk7eDo55dhATi3FE2fSsxyQMxLNd+HXabm9j7f\n",
       "buBxUMVSy1JPevnsl0mGMF/w3XF5u6tOLVxSDvFXcJBDxfOO6Zpk9qy0jj91fsZFed56jkhV6/p8\n",
       "ZIpSezrNEXyqiDeG/9xWgczGrEvxwNMjVJPpzfSmg4CD6CgNMV/8p/A+NjquB1owHrPBE3lzXsUp\n",
       "lrHPpv/PGSpTJIbbeTG5CAc8xfYlVBVeNqhXQ3+GKleCyefhuXNc0JFIOXvslCeyrNLl8ah9Kf9K\n",
       "EpC4bimuM0DMI6u+zukMNgT/gUSYzLuwaBf8JZA8q36Eam3MSRq2qIM8e92iZvf2dOTOnSrlAkST\n",
       "iYjx/BzhAUkC25Pdr3VIy8N4/5r/kpJOQSNf3yeIa0CZUMMUat/JOXmrmAFatyvl42Z1FQhNTSH3\n",
       "MbZbSGSVOSDwAFSBtlcdsSR9+bL4YckAJ+/HabagNCnMu5ChE8ZCq27HlEooeJoEfOd+PBpYGbv8\n",
       "AGiAc2dY4V7O2H7Kqp5Yyc5xljLHGLIhppYTnBnwWataoapuK6QxiAjYWBL/5Hg+NHRH2O7SlCQV\n",
       "FQjwvDUEr9aE/sMLbC4tzyw+v6vGzt7+vsHLDXdE1+yCXYip1s0FmJ7saxLM+P4PhPTpMBLWb716\n",
       "gKn3XV4wEVBsiiszLfjU7+pxslgwslR/6jiDIY6kLPjNymVMt2ayr/Vgu9qHzzB+Fc4DwWFoDiVE\n",
       "soSHIrafW+Nr8GYQsPm0qQjQ38XVJBlFJ36pTHqPq9CnHvE0VyfDvTZp9f5gtv2UI1CbzN3DpvoN\n",
       "LM8dxI2AfLE0y9dyiyK7ehScPI2C6KmGS/vKB16Q7AR5p77TUCwIwToTxbi0Fjl65aLvv3tivHW9\n",
       "ppucW/cuwQVQdboriA6lHIUfwSAa8Er1Bnfza+kSEDR6vZxGSr18E+6gweYJ5OyESEe2RcNnAK9B\n",
       "92LCbIeZ8PdVin3T1Rg+wFFx8lqx63rtoo3GkK4Hh7W2fPa2Cz1pcADM+peqr8lEqdG2FKmiaY5c\n",
       "C7pEqgZ1iyM0zytX/U9lRgGme5u3y/HkBU2rlHfI4xQUVw08cAwmv4sfJ/zCBKhqPYMQ5ASXF8aN\n",
       "xrOs3QbUNqU+2SKbbqOYUU6bMgYA+l0hJOKaFhE9Ts2NIPXliu67VUCy0G9j3USaLo2/hFpYRCxo\n",
       "nk3tOAonwbk3oAAAAzhBnspFFSw7/wAFlMSsDGiS0gDYilLerf1s2GktekBirltTR5P92i6iYGOL\n",
       "wuWavpqiGKqRZd2WgGbpYANuqxRbQy5D5Dnr8C7lUI/bHyNckua/nHVZ/8YV7Pq1bHfnSKV6RA+P\n",
       "J28jLLH9a+UrwjrhyWl15A2g95cbJJ+5n2TO7WmDDBIsXtplIhDBWydQiW4yU17CzZMTey/0FLOK\n",
       "aAxCvd6cr3eq0xqnuupEsgp4gtBi/dWSECZGejeoJhWr1MoFxKvidd+KFdF2oN4p/StFcavlUTFs\n",
       "fx+gfrSics7bukfFjcWq9nv/knQv1NLyTMsPSLI5DDd7zxRev74trvfxRWl88V4N/ewPQecQx0kd\n",
       "6L6zt1E6V0hbIoqnAx9CEsr1ZWRvicis1nlRmwMQ5greL61+nG5lrxubzQpCEXbi7H7UgTuLsB3/\n",
       "YNSgjLMos9li3fuVKplpRiW0cEPJfBY48dFR2Q7FWfNXDWZlDMqFH5VCCLrWEvmydVPEGC2cBL+N\n",
       "09RV8SlYwXoSloXA5CSRQnXqmuFAY2jpyx6Bwdxh7WN6/JbRonpKfwxXiD/JiiyhY/1iPgT2Mi8c\n",
       "GQXjFaE8qHqXoX2koo/Lq/pwC16wk5SCNfgyZ7PRQQVu+mTUk+ApvE3kyvAGSlJTgn/ViMCPxQlY\n",
       "vcEnKAHVhKdyHOHScU8wjsvn+Y+SGfoBygqQSwBZcqLQyT1seD/+zoJ86h7O6w5SJ8Gs0hiW8M2m\n",
       "tHNmRZsmJi/KjMYXLdd+XOkWirdXrN1x2urGLCmQibjel7tZkzDpsxxEiVy5qdTVhx1eJ6JtC77M\n",
       "Q+KYCsHrrM2y74OCGoZQm4UILKTc0pjvXm/plZcmuALWITyNKJSZ9TDAGphSeuq2ypQFo7+tbzec\n",
       "YCjM+JdpTUh0oiVFXiI5epIB2KyNkeuRJ2U7OpZSTcsCw/CErbMZs2PPezf310j9K1yrLI86Ooxw\n",
       "27huYlMDazXMcORBoISJ4nWVFeDZx6WbjV0c31985hgybt5hpb7Px7SjhGVPpCraUpctTFf0sYZh\n",
       "Ge+/eHY7N8p3A55BkL/yFeq70FOscZ/BmaGByxQ/EWPyEeUc4QBnwQAAAgMBnul0Q38AB8SuafoK\n",
       "31pE8pcARKtSOrHPiIE69aLem1enBAq31dTHhzr0OGb87UQ5t9QO1DUdtvmE4TztmJ4/EHcN4zO0\n",
       "K6d5075H5CVxA3leiHI4qmzuOukUURLnINf3WI6I2AG2S/7xKiGHYHFi9RXpXuaM6WIM9ziVOE5d\n",
       "0dIIVqZTHKypKlISrmLvLBtuKe7On10KZvar0O5FloYoSP0l9UsSJGHOitRgIr74tYWxXLsgUz71\n",
       "QAeT1Om/fq/C17O3dJZWuoM7QAzocZ8S9cksGWjA06znSHiUWTJycwKtuSaZXgj58AsWQ4KD4Wev\n",
       "uqmYGmfUICTM8a0QJME2aM0psMIgtOQuyOKx/4umOXdUFoaFpTozGHBvDDYeX14z6D38eA7PziJW\n",
       "cQYJanfhh2nj0/p0dl7LD0qOsKULRmXU5BN8LmjYzRZtmG3AZL4yo8trKGZkLBgzdHioqud/oaQk\n",
       "Gh6+2GJXI+z8ocZ2mnyjbD/pJ8NOb6TJpuwZ912oToSpRbE0QZga3OxVVwq97YbIXnY0KV3KEO1k\n",
       "uweWzlw0xnF5ysUqhNplGnWLaa4zZgyqdLpfPD0c+qLU5DEPJOdAKg5QArYSq+fOAONjQwUe4sZ+\n",
       "9r+QrEVBB5COhpSBRr3h+nYoQuRtyyCMGAUBjfFOZayyfJEpPn0ICuZYBIADUgAAAaYBnutqQ38A\n",
       "B5e1hGdahzUGr5B3FS/gWMRSMJTBPFF+6vAwDzAADn3P7HyfJXYNqA4wUYlHm14NJ6aADd3v46Vm\n",
       "uDIrQscEOYG8wpq5bfdnFlTDGoD9Aj+QFN4k6UW5rjwEiSv/Y7qH8PIPjM0lvPQwl7yYrKohaDin\n",
       "8bcDCXWmHosv6jHkbxjroFghxfUHtP9mXk8It0M3nwJEZShOywNRza0AehCjcngWiwQwEhQjQL8E\n",
       "jZyNml4nPyEv+wMYT9gwvIDW8z4rGUSCuicTzyNO7HiRe++BTN3acHcXjPeQo2YuePdgsyJBQ52y\n",
       "hzfU2xnZXpNl7nIHxG33RRoCwl2JLbqwKTn0Ka9UOsIgxcfNLSqGM1ial3d0BqYASepv4Kk8eejm\n",
       "bZknVd5wfbS1CbmL2aE+n8z9Wr0BsZBpGcBHm2CvJv2nckrb7a12aWOKBIDo3LgGF7NEpmi1sFJn\n",
       "Fe1IJ2e+mHSUkFlHoRFKeCYTJhy7VYTP2K4Og2lGe29odDyOqQ1j6boQUggh0AVG5HUPCb4+8nLo\n",
       "3zD5LybCfJy//fhMJiibgAAABRhBmvBJqEFsmUwIf//+qZYADPUW68BFTfNgOAgxhN1ISdm4h2Mj\n",
       "dFgtqc+xRFwUXHAIbHVvFs9PTcDfOKrxDOvzvYRlYgMuhb9Gotq3PrJSNzgNR2V9qOu8MxPpYUoj\n",
       "tIqJFlwKYLJIhnIo+sQO58bu9TYcMvofiYe7EQdX5tHqx4bqYqX+JvkAut9EfcjWB2pSIJP6r6KJ\n",
       "mBoJsK8LbhoZmpMTMvB5e9l+WD7YbFkhovJZZI678j21t2IbjFJtv8lXbAV+AC7AwJbBOayi/Xf/\n",
       "G8fhfzIkAGWBw6r7yORMqBHkIsmJzfZC+qcDMk2hkP4t80mQ7w25XmvTsmpcmP49Xs9bteqrsF/K\n",
       "IFLXiOsPrV9ekq9hGeepO8lITcEcmAESjWybfLWcNFibZ5cH3g+H/aPlTvvwSR3JHlOFrZENm9c+\n",
       "0UfzWThhFxsiQ8urjiZ2+VUTjPgjVE2N+MYUmwN9kfHmLA+d8y0jA8Jy9GPGjbNvQTXpdA5HjWmY\n",
       "rdMCVZC40UHhIc/g5xKh9Q3+TYHarHF9XMUA1ZE9XZKqAPlr6Gu/AHpP5YEwE5Kw9Zf/P8cQfOnS\n",
       "KqnQNx44DKZH6R3iiRu3rtRKrP2wjEchdxDpmTZGexWDhfYgWN+WwTcrHRGzAFFOhZWOmeBpiQ8j\n",
       "5pgm+L7g1eSLCWmITtX/XbS8woBZkHMOqj6satlP7SB+2kD6+0UgtIXfLoVVke7aN2qiabzIKY0R\n",
       "itL2VPITszKj0BsSC9bH4gMulE/wReDXH5UosZgbemibQe4a82FPQy2woUtOYRSWS8CyV4HBu8I/\n",
       "SRkKOFt8lPNrVTDaK6uiIqLVRXt/aXy6qexYLvZA76MWx6ugKKt/XtNDsJudM/vFf951W3wWaPAd\n",
       "cb1dlrSRsgSZIP9CuVYhZ9OuvLUOY4cqGtw6+35bd0SNqCf1UVuXEZrOx+hBe8zlzMbLYfBiGhWE\n",
       "FwpfhtwwqeFl6ynoQeWav+fL9wYVwRgUxKBaTpqNnoko/TagZFh1mnPX3tfj6ihWZUP0QpHPh79e\n",
       "rlIbnEfRh9aCHoQcRo91rH8OYtSPdAIiFrL/jdg/VSUZ+isgVnoc4dNPB2s1CRW0dWhf/B+7mhRs\n",
       "upV42A0eyfYyuWlyyoCTzv6PVliXp6DfRjB6KHDFiXDqX2I8PjqxDf+lHs38EGMiTTiN/wcf91+j\n",
       "Dz7A/VZMd3Wmmr1Pf7eC5wxfIEOResZpS6NoI+mZkzLJIyGLtYE+2sPAphHT2q+mE8EQCWElM31C\n",
       "qcza4taqu4/WXRa8/lJg3wVZM85Mt7N7pCuQeJEu5Y/CQXOp25ZJ434UHKmk1SaqykDnLcd1C4DE\n",
       "ju3gElNZMbC291f3Tr+7TJfSTcu6vlK/SUrwq8VXaIeJVL9KEkge/mzTWaI/C9M5rVaOyRmjhXdk\n",
       "BFffYYJTCK234+sQmKQKoO9ivHlcyhvJRd+/gOmrJEPMGx4EPJLivg6RMaJ6uGtA8WMTIqOAvPgZ\n",
       "6uTqtE2RxHhZGJ9DpzzDvUMfnyiRFYC6/ekuLodBSe+D6cbZYNjUb4eEpFInxi20XkY3bGNt4Dco\n",
       "ArL0GIkq0n6fbkRyhwOwY/1EiBR1eKzNbmOo9Xz4XiAxNUwf5J8LCoikJgm5oKcSPudszcIGrna1\n",
       "y1ek+9PbmVXgGK+oGP3HnUyw4Dntj3xqS9/ofD9+7TsZwyAKDHHAmuF4TWYcXuAaGmIb1mmwMS6T\n",
       "oTDOnTHIkRIKIeAIeQAAAv9Bnw5FFSw7/wAGfBIAq+CVvO4kzDb7iXVDKwidSmzI2gkQbJAQrrhD\n",
       "khe3n3oY9sk06iUUzXlhpJYheFzNKImJ1xhuq9DKKGfVgXDyYpsAQu+fRYLwn6C9tYbzOIvmohgP\n",
       "ex3pt2w5TT+8wQ16ELpNvV6KjgvY9YcdiGSkAl/HwUqsHuBDbqgv1uJg0tCxUv4+cQyfRL+pA3bf\n",
       "s6oMr/MXoTvF9/WKNYHF7OxVxWSTyYhtrEx0YzVGSebUUDtnFTxEK9kb3BK8pIv5l8AukN/km3op\n",
       "gXqUXNDJG0fRh7bERI2qINy/SddV8ROHdSFZtpBlXPnStAiZbfWWr/G2IGS+FYyAccZhvImQOpgx\n",
       "P7hCmAs9HeqggvMzYDgvsxGc2LiJHFkRcP8fwc4MBiHG1mAKOZOt4VYcY9H8FokIZm6LB1u/nV53\n",
       "OXSKzLUK2vWRtboYHKBpCjhO7u8pLw5pBc+eyXHM/gX7SIlISPJ2kA6r9llqKeCUE6jqHjJ+5Lkd\n",
       "1x/VLU8kBlsmN1lN9gZ7UDO8pl7UYfs+24qB9Bkfi0PnvKjI4vYyXQUuS+VFGlBlZhVW4c9p2ev3\n",
       "RiHpgvCNKFw7OraIZPqURACVrYkdAAdcGXLXL2/XbGfo9hF9NWDwli+Ta0j1NMyhdzQfGr80foFt\n",
       "Qp2axFxeFKknyiWZg43EydIjevsVh4GC8dqyzd5BqWxctqTb6gfjj07Sj24DYXHskkV76a5M1/Cl\n",
       "aDLrkMjjLAAgI1l9unK1/rDa4AWd6XnkWvFSQom8vyeuITQpx6C0Y/RqdQVUuvtgI8UcK/LP3Co8\n",
       "BCUEZkjdu69RcbeEZWZREtPHPUZ80iPE1C0Pm7PpNC8uZVJ7gBgiHg95QUNuTbmS9DYL+Awlsmb6\n",
       "w4o6mHnL4VHPMi6C6kTLGveLf0nYF/CGkT1TdQNhD9f6xf7yjmGDYDyPp7bQkLunzvCD+6dQ4YFk\n",
       "+qVZ8JrC4dzx0VcfF7N2nCMbdyf/dz+yu9uWjLf4s+gRbGqnfOrFHKALaQAAAYUBny10Q38ACK3l\n",
       "+1EZJ5Zgu5CmAULAANFhIMk7VcCI/caXtvabj8OeCytFo/t8yqxqOT4vbqnsLmIWuufeXcwQHDki\n",
       "JFXe2eQErV0926DMRlIFn7QS/GTWNFhTRwuoJpOwuXTwyOZSihIaBZoT7qO6nK4u6se8s/A/8Rez\n",
       "K/37N4ZbPFKn3dukmpugVJy5GD1WnJgrJD3xCI5AarwrEef58clG99aEsgx8fqK/1geUG//TLOzt\n",
       "4FrPU0cZ6wk0AcZyYDlIYOu61Jei0gS6frAYbNSERd2VGXT0oY2h4L4dE8zvUehz9sK+rsscqluC\n",
       "GrnC5NT6tGedqEkYCFRxomVaHjZzOdaqoOmHjaPSPHJWi5KlNeazF2ElTNSDC7KeB6jYJsaFPolC\n",
       "qPfv/m8IEEask2rdBan3ukcNU92l4OJVQxj4K9+DjMHT03ZnmV+tWQZv8K5tPeHdtTKRdAVpnHrY\n",
       "Wg5u8lZFQMvGYiCuevEZGX2bCCw8OGPs3mH626F86TKyfuqBWwAAAj0Bny9qQ38ACOwJOUp6o0h4\n",
       "d3l8AHdjvQxBo4qSzxONTzs5WQ/nkiC/AxQuit/bhRihp1G9RDS5jahtV8Y+oeO1vvZwbXx1FxAq\n",
       "V6UFIu0XDf+JXuxm1O2ETxRVEn8dLYM8WN1HABKfhQNrD1NI0hTXhQjDY9AUknB4KL/8krTFI3sE\n",
       "c01KEyeijv5dfys1FeGDWLKdLy/hBGv32HeAc1MyA9hZRCFIIE5WsZ26uoNajH5XmHfDc6HowC47\n",
       "UVWDZJkbXiUJXATJ8sjEE8Bu8et8+hRYA+noMy1E3qoVNEVY5f8TAY6UK5vCFK4TVwpGY8udwDi8\n",
       "bHi+UZi9OGpavvJ20Ou5ZXjg/8a4VKnw843W79MC2kMotKg8fZhW8tBMz3JaO2RE067DdBYehfx8\n",
       "l0fVWx/KhEj6xhoFI2cKKD6cjTtsYCcItclhMnWkKvftanolp5PBAYvaNWm1CFFesdMKRqOa99st\n",
       "usrnhtOrpPkFlo1hGeASWu4JZU7BhemcESunS+eoJzX91pWjSB0A9HQ2W8T1B26uIMQw0CIsp4PQ\n",
       "0ZG16nRxMXBHHEJXABR9SctA79vQK9tUtOMEKdGeHjP5BqAThT4hV5YBjbHWXaM5/r+U6ox6aU0q\n",
       "UnM5C/QaAr4OO1ZcRfdTSTuDzU7WKhtRjsC8j/JlbUbXStQV039m0rOPzjwipO2Ak1vm/0QjXeC6\n",
       "ZX0m0d03DT7IG9/H9AXg06I4mq7c00ztlalkZ5+mb7CERCD47x8/NI5QAScAAAN+QZszSahBbJlM\n",
       "CG///qeEABpbV3IK5UA38ioLUwdxdc6o/F7mcmH8qMxiLE5IG3P947Jg3VC8V71x/+rixEVtASEg\n",
       "xvLVfHlBoYxqXPvIAwODBx74xtq94n/RIo3hfqsD1LuYLwbxetCZIpe0wK0a+i86hJMsd0mLU3CY\n",
       "5xNOJnv7tOglpFRPsZ+c6TwUk65O/Zzrmduuez1zvhLrlry4PVT5QD9dx+cEhrt62AoNEARUYI8W\n",
       "A/ZW+J0Yntpiuc45NivRnMw4MolyR3HlB4fPhEpfUYtZqjO7/9mMmRfqoyZ4y2PuzfH2j+CmMkrB\n",
       "kEVS/ifUg6U/MhREDkEwhSoUKZFRWHKpoLUzkywGrOUwV7KQ3LzkIJePZNMEyz/6bRigf0p9BFO6\n",
       "ocFiXolsI+zBkfIxWhiGNg7i2zvTO1xRQNtdtLC2NOqGFbKtl/Kwrdpf8ZYLuLP3LVLyvoGhsoFp\n",
       "hvVT8JUYyqCAuh2cMapZ4NWxs9O12KLpz+2LWCLeLlrbz51m7P81lUHMKzR/SyDH/hwA25s2WsEO\n",
       "eGk6L1D/b8GxBa262xnQq/ugsct+Jklt9gHBf0Y+l1Y7fDXrUvmPeMaL9BRHat/Li8eooI3b4SEc\n",
       "Lq0rzgUs1bCkSMfPRari2aWDJ7mr7VRXtp/gklj5jerPFu2M5fD6ksaT79koxY+pImoDB3ks6Nkz\n",
       "74LK/oehmgLL+B2a8ZEP4vYpleMOixBKjMH7jQsebtOXPTSQQNUmaJN/2Fq4B9UWNQw0YbUzt4A1\n",
       "Vh5ncL/OcscVvNrLNxt0dk8saaiiQO4cRlwNnbwz/8n4DVnSa0GAw3jwfFhv1cs6hLkv+BOQkUHc\n",
       "oDi04hau6RMgTLg3Sjwq6AURJJhqS6jvPSk7DM43xNttZmtuQbpVm2WO8HMEA8h/QoCKb4lWljcz\n",
       "mbx5Z5x7skUxtbyIFIwetOWhyqQx6sAcgUFqrCckHImimqSv0phctIDt2md9IpP/fwoKW9B285if\n",
       "IwIT23M9ZAinir/e/dsImPJ/Cma/ovi88W5VRCkjjvu26uSI3dl4Szr9VeF+RzN273DPqGRlb5FY\n",
       "cuVce15BY2cVuGKDVp23RyraiWuKsXBoYAO5Oen9eJInGfw0yExMC3faeBRAyNTDMxcnvkE2A/fD\n",
       "KYsnBD7HXJ2vMUIcfTsDStIPH5eGto+hGD8VEAUkAAACYEGfUUUVLDf/AAkuRfHn8/ogOlesQL0H\n",
       "gjEsTg9VVqoinW38L/oQ5mjr3ro6xdQJurS8OwoW+VaDb+meG5pYWsAUdfdunZm6ylZhQdwU0sKW\n",
       "7Jn/L9G5pKy1qFRAaG0KV/iAG55cEDCSArRFzRr7+04EeeDWkNUVenpg04aHy1cy7gYF3CoZWRHB\n",
       "a1wXbcQnXAONsoUoLeEjk4pkjwtLr638cyQrbjLi/uHyqpmVEOMbrqwLOnFeAjLZzccwCQwdlBX5\n",
       "g9qka2OD5LIxi+tT1kt4tJ8SV0n4Q8jd3elWGw2suFBGcOmNtcyvk8eqKsiiEW3FBu2VNtUR1eQQ\n",
       "/rfirZ3yi1hCjcuXT9X6EX9XE8Rsk+fJJjwwQMW7DoijwU1GFOef37SbX+1YVJIvfBVvMHhjx7/H\n",
       "3bBVnHVyN7FckVpFjrpDuIdSFpda8LrUq7pNkrQ33wsM4Llbt6y60oGhEezCxpCVjLJ/0Wd5MQV5\n",
       "SG9UMmPqcMOp2EWIEVwTBCceoLnoGAUHZ2xFqSSzxSgBCQ/QjK0KDhbMTatKBXI0TpLCFruv91JL\n",
       "8ql0RxzF2I0NkPD8il2BgryEhqa/KIA/s8p83AR3bp8OVjUY0GehR529FicdgF4hOuo5Th5P4xyY\n",
       "QKksELA2nKtTANXh/LZ9zvjBDgBbJObF7dUZps5vyBQ33cvhnX6svkTrwGAmfq7Q6TbG/NKwJXUw\n",
       "B1+HRJvw+hxsnfTn3XEoxZsKbYj1OkbnaYFuNfTW7w9c96jPncSPX6GM5l3V7B3gIm339OTUs2bF\n",
       "VDUNbbe92WedwT/T4CLhAAABmAGfcmpDfwAJVJdr6e51GoAjgRtGiFKXVJC6yCoiSOZ8m2ppvdoh\n",
       "e30xQIYZOFs1FM0X19iHkYDYOMIK0fj3Ki3BZA9LHfGndeWL+EveFzqb9BwdHbUzGAowB3gcAa7d\n",
       "5X5Kg5swdugWljbhid5aRYO7L8qWsUm2ek5pIrB12Atpn4UiSTxdd5iCeHxdZxMFKORGNelOIh3B\n",
       "4HEte0lxddDPMpkts28xaHGm30TAv6HgUorWkt7qBozIRyGxBuiktfF9I9iYgDZUZr2O/FCGXnxi\n",
       "LOcjkpAiTamQr4bvoGJpYM4q3GPnCexfuc91NO4lxRkhHNaw1t7/tYW+rRnT8WT4LaAMHmedRURH\n",
       "X58PDio3Ef/TCv6eXb9N8mqVWf/wWX8kAEhMm/ogyK8BLYFUmuY6kAjd3sKBI6hsB0SsqHbgyrgl\n",
       "ONKzbb0cJNCH1tBtQClx2R0B/eP7rxwZe91nr//5wOIMiMOinfyjYIwCDEXg5Y54YLJC1TcIsg0Q\n",
       "ahKJCiCcGsa52vRx7qHXn95CgqdgCcc0NYDRgAAABBptb292AAAAbG12aGQAAAAAAAAAAAAAAAAA\n",
       "AAPoAAAH0AABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAADRHRyYWsAAABcdGtoZAAAAAMAAAAAAAAA\n",
       "AAAAAAEAAAAAAAAH0AAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n",
       "AAAAAEAAAAABsAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAB9AAAAgAAAEAAAAAArxt\n",
       "ZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAABQAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAA\n",
       "AAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAJnbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRp\n",
       "bmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAACJ3N0YmwAAAC3c3RzZAAAAAAAAAABAAAA\n",
       "p2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAA1YXZjQwFkABX/4QAYZ2QAFazZQbCWhAAAAwAE\n",
       "AAADAFA8WLZYAQAGaOvjyyLA/fj4AAAAABx1dWlka2hA8l8kT8W6OaUbzwMj8wAAAAAAAAAYc3R0\n",
       "cwAAAAAAAAABAAAAFAAABAAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAKhjdHRzAAAAAAAAABMAAAAB\n",
       "AAAIAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEA\n",
       "AAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAA\n",
       "CAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAACAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAA\n",
       "FAAAAAEAAABkc3RzegAAAAAAAAAAAAAAFAAAE/MAAATgAAADmgAAAp8AAAGTAAADpgAAAr0AAAF3\n",
       "AAAB3QAABEYAAAM8AAACBwAAAaoAAAUcAAADAwAAAYkAAAJBAAADggAAAmQAAAGcAAAAFHN0Y28A\n",
       "AAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAA\n",
       "AAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU5LjE2LjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ganime.visualization.videos import display_videos\n",
    "display_videos(generated, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee844413-b838-4f46-922d-a9342e7d1b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ada064-913e-4f51-9876-81a22bb33c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
