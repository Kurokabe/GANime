{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5832b4-d402-4b11-88f0-eceff0702222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdcf163-d736-4225-8fdc-ca8b8298ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b04bd09-dbd0-4417-9e53-39d4af819453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import os\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import  display_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542c0c07-9bd8-46b0-8fe4-6f23fed10569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 05:22:23.041299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-14 05:22:23.412151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22310 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([200000, 64, 64, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"../../../data/moving_mnist/mnist_test_seq.npy\")\n",
    "data = np.moveaxis(data, 0, 1)\n",
    "data = tf.stack([data, data, data], axis=-1)\n",
    "data = tf.reshape(data, (-1, 64, 64, 3))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b1098e2-7d6e-447d-9d43-3ae3f377f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.data.experimental import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa03c438-06fe-4ce8-93dd-525c2a5d1924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293c3e65b34442a19f639029504fd056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 24 files with 8334 elements each.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643728b912494bc3b938fbe58ada63e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote 200000 elements to TFRecord\n"
     ]
    }
   ],
   "source": [
    "ImageDataset.write_to_tfr(data, out_dir=\"../../../data/mnist_tfrecords\", filename=\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eede51a-690b-41bf-9a02-54c2fb7634de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"../../../data/moving_mnist/mnist_test_seq.npy\")\n",
    "data = np.moveaxis(data, 0, 1)\n",
    "data = tf.stack([data, data, data], axis=-1)\n",
    "#data = tf.reshape(data, (-1, 64, 64, 3))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda88d02-79a4-4e17-a079-4fc29198e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.data.experimental import VideoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d71722-a735-4f65-90e5-a93719aba98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293c3e65b34442a19f639029504fd056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VideoDataset.write_to_tfr(data, out_dir=\"../../../data/mnist_tfrecords\", filename=\"mnist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
