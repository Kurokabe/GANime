{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7919977-e3c3-4002-b90a-21f0f688e263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a2ef80-d0a8-4e27-9306-f8d5309e0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80bee5bd-c3dd-4c1c-a7f2-086b160f95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "from tqdm.auto import tqdm\n",
    "from skimage import transform\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import display_images\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0b2ad1-d2ca-4d1f-ae99-fe2413c17fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"../../../data/kny/scenes/01/*.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6f7499-11cb-4d63-8724-35e205d6df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = sorted(glob.glob(source_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fd1890-39e0-4a30-a4c9-993776b53e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_video(video, new_height=64, new_width=128):\n",
    "    n_frames = video.shape[0]\n",
    "    frames = np.zeros((n_frames, new_height, new_width, 3))\n",
    "    for i in range(n_frames):\n",
    "        frame = video[i]\n",
    "        resized = cv2.resize(frame,(new_width, new_height),fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "        frames[i] = resized\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640ee2f0-7082-4219-a04e-a8da9676709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_count(video_path, manual=False):\n",
    "    def manual_count(handler):\n",
    "        frames = 0\n",
    "        while True:\n",
    "            status, frame = handler.read()\n",
    "            if not status:\n",
    "                break\n",
    "            frames += 1\n",
    "        return frames \n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Slow, inefficient but 100% accurate method \n",
    "    if manual:\n",
    "        frames = manual_count(cap)\n",
    "    # Fast, efficient but inaccurate method\n",
    "    else:\n",
    "        try:\n",
    "            frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        except:\n",
    "            frames = manual_count(cap)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd947d3-1933-4960-a711-90d8f10e5ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e206952c7e94aa384397e0412f3cc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_frame_numbers = Parallel(n_jobs=-1)(delayed(frame_count)(path) for path in tqdm(video_paths))\n",
    "all_frame_numbers = np.array(all_frame_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fd7a4fe-bd06-4144-a2ab-58937b5c4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_to_split(array):\n",
    "    n_elements = array.shape[0]\n",
    "    range_min = 15\n",
    "    range_max = 25\n",
    "    \n",
    "    lowest_remainder = range_max\n",
    "    lowest_id = range_max\n",
    "    for i in range(range_min, range_max):\n",
    "        remainder = n_elements % i\n",
    "        if remainder <= lowest_remainder:\n",
    "            lowest_id = i\n",
    "            lowest_remainder = remainder\n",
    "    return lowest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a19a569-df9e-46b1-8cfa-f9218e06bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_array(array, number):\n",
    "    n_splits = (array.shape[0] // number) \n",
    "    if n_splits == 0:\n",
    "        yield array\n",
    "    else:\n",
    "        for i in range(n_splits):\n",
    "            start = i * number\n",
    "            end = (i+1) * number\n",
    "            if array.shape[0] - end < number:\n",
    "                end = array.shape[0]\n",
    "            yield array[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4de5578-8283-491f-b024-21449d3c3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path):\n",
    "    videos = []\n",
    "    video = skvideo.io.vread(path)\n",
    "    video = resize_video(video)\n",
    "    video = video.astype(np.uint8)\n",
    "    for video_split in cut_array(video, get_value_to_split(video)):\n",
    "        videos.append(video_split)\n",
    "    #videos = np.array(videos, dtype=object)\n",
    "    videos = tf.ragged.stack([tf.convert_to_tensor(video) for video in videos], axis=0)\n",
    "    return videos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c412b34d-be81-4505-9520-44cb6c51b8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b6cefcf5a845f69a74abad5c2d01fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 00:12:31.633489: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-12 00:12:31.995984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22297 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "videos = Parallel(n_jobs=1)(delayed(load_video)(path) for path in tqdm(video_paths))\n",
    "videos = tf.concat(videos, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b31e4b9-0d72-4cd4-b696-472dc6e8ca3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1506, None, None, 128, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c9bf8-5e8d-4f42-9513-496ca7cf2bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
