{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c995bfd-ceef-4145-a103-c2a064be737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a9c822-ecf1-44b2-aaf6-c7122a777180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639df7f6-3066-44e2-a9c0-60bc80e81a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58672f89-39c3-4e2c-9960-c51fad5e2709",
   "metadata": {},
   "source": [
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277a395f-1f54-4d91-be02-214f698f0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "for device in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f01a67a-1183-424a-8eda-986b6be4173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 03:53:53.760566: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-19 03:53:56.621668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.622919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22308 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:25:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.623837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22308 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.624735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22308 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:61:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.625613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 22308 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.626479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 22308 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:a1:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.627301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 22308 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2022-06-19 03:53:56.628172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 22308 MB memory:  -> device: 7, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import omegaconf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ganime.data.experimental import ImageDataset, VideoDataset\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import display_images\n",
    "from ganime.model.vqgan_clean.experimental.net2net import Net2Net\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from pyprojroot.pyprojroot import here\n",
    "\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64804403-13f9-4157-9dbb-757df9448525",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b530068b-b80a-4553-b0bb-5ec609da7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(here(\"configs/moving_mnist_image_transformer_huggingface.yaml\"))\n",
    "#cfg = omegaconf.OmegaConf.load(here(\"configs/default_transformer.yaml\"))\n",
    "batch_size = cfg[\"train\"][\"batch_size\"] \n",
    "global_batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "n_epochs = cfg[\"train\"][\"n_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0216592-8406-46fe-b5c9-bfb39ce04b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = 10000\n",
    "num_batch = dataset_length / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466810d7-a54f-4cf3-90fa-22bd15c35e25",
   "metadata": {},
   "source": [
    "def preprocess(element):\n",
    "    element = tf.reshape(element, (tf.shape(element)[0], tf.shape(element)[1], tf.shape(element)[2], 3))\n",
    "    element = tf.cast(element, tf.float32) / 255.0\n",
    "    first_frame = element[0,...]\n",
    "    last_frame = element[2,...]\n",
    "    \n",
    "    y = element[0:3,...]\n",
    "    \n",
    "    return {\"first_frame\": first_frame, \"last_frame\": last_frame, \"y\": y, \"n_frames\": tf.shape(element)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd301a6-c566-443d-879d-e58c1a2ecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(element):\n",
    "    element = tf.reshape(element, (tf.shape(element)[0], tf.shape(element)[1], tf.shape(element)[2], 3))\n",
    "    element = tf.cast(element, tf.float32) / 255.0\n",
    "    element = element[:10,...]\n",
    "    first_frame = element[0,...]\n",
    "    last_frame = element[-1,...]\n",
    "    \n",
    "    y = element\n",
    "    \n",
    "    return {\"first_frame\": first_frame, \"last_frame\": last_frame, \"y\": y, \"n_frames\": tf.shape(element)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "293f1357-eb57-4561-9f54-c10912f1dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(\"../../../data/moving_mnist_tfrecords\").load()\n",
    "dataset = dataset.shuffle(dataset_length, reshuffle_each_iteration=True).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b06c992-9332-4690-b5d3-0deb9de24c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(dataset_length * 0.8)\n",
    "validation_size = int(dataset_length * 0.1)\n",
    "test_size = int(dataset_length * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf5e800-4917-4873-bfe5-bf6a69ab3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(train_size)#.batch(global_batch_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)#.batch(global_batch_size)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)#.batch(global_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210fd67e-fc3a-4f1b-a4b9-7c19a8032940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_data = next(train_ds.batch(batch_size).as_numpy_iterator())\n",
    "validation_sample_data = next(validation_ds.batch(batch_size).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a298d58-014f-498f-b662-7a13edc00ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(global_batch_size, drop_remainder=True)\n",
    "validation_ds = validation_ds.batch(global_batch_size, drop_remainder=True)\n",
    "test_ds = test_ds.batch(global_batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac21e84-38a8-4c33-8404-e8e118ad5be6",
   "metadata": {},
   "source": [
    "train_ds = strategy.experimental_distribute_dataset(train_ds)\n",
    "validation_ds = strategy.experimental_distribute_dataset(validation_ds)\n",
    "test_ds = strategy.experimental_distribute_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aa7cedb-d229-415e-9162-b4ac9dc89fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.utils.callbacks import TensorboardVideo, get_logdir\n",
    "import os\n",
    "\n",
    "logdir = get_logdir(\"../../../logs/ganime/transformers\", experiment_name=\"mnist_video\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "tensorboard_video_callback = TensorboardVideo(logdir, train_sample_data, validation_sample_data)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=50,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "checkpointing = tf.keras.callbacks.ModelCheckpoint(os.path.join(logdir, \"checkpoint\", \"checkpoint\"), monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "#callbacks = [tensorboard_callback, early_stopping, checkpointing, tensorboard_video_callback]\n",
    "callbacks = [tensorboard_callback, checkpointing, tensorboard_video_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b4a1d3-8c67-458d-ad52-ecab8390438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_sample_data[\"y\"][:,0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0fe4f08-4aae-4c30-bcd6-cf8f3e9ed40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 64, 64, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_data[\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66be9456-796e-4618-8ed2-26257f58773f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 128, 16, 16) = 32768 dimensions.\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 03:54:03.167757: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-06-19 03:54:04.106762: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = Net2Net(**cfg[\"model\"], trainer_config=cfg[\"train\"])\n",
    "    #model.build(train_sample_data[\"y\"].shape)#first_stage_model.build(train_sample_data[\"y\"].shape[1:])\n",
    "    model.first_stage_model.build(train_sample_data[\"y\"].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa12dd2-20a1-4760-b392-9f10eb3476a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da5313ea-35c7-4f99-9413-10ed7771ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 5229 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936da37-67cd-4b81-9744-2f4402db1376",
   "metadata": {
    "tags": []
   },
   "source": [
    "for i in range(10):\n",
    "    pbar = tqdm(train_ds)\n",
    "    for data in pbar:\n",
    "        output = strategy.run(model.train_step, args=(data,))\n",
    "        pbar.set_postfix(loss=output[\"loss\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a614b-a07e-404d-82eb-c46749467136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5dd8b1-39db-4d97-bc84-6ae46631a646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 03:54:20.837157: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:54:38.796953: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:54:48.967272: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:54:59.097898: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:55:08.623767: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:55:18.681664: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:55:28.812805: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-06-19 03:55:38.381557: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 94s 94s/step - loss: 195.8095WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "      2/Unknown - 113s 19s/step - loss: 171.7492WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=validation_ds, epochs=cfg[\"train\"][\"n_epochs\"], callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cec6e-b287-49d9-8848-ed32d695e3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_videos = model(train_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d399fa7-3a52-466d-a742-04f00816cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(generated_videos, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583a6a7-7d07-47fc-9b71-1d718f48ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(train_sample_data[\"y\"], 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59bbc9-96f5-4e93-80b2-ae760b068cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_z, indices = model.encode_to_z(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65336fd2-1a64-4635-ab2d-6275749d1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = model.first_stage_model.quantize.get_codebook_entry(\n",
    "    indices, shape=tf.shape(quant_z)\n",
    ")\n",
    "decoded = model.first_stage_model.decode(quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6751d91-e4d2-44f2-9778-8c5b23d698e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_images(model.first_stage_model(images)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab52bd5-c95e-4fc1-9009-76e1f7f6425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(generated_videos[:,0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576c96f-c0a6-401b-877a-5eaf7b69ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
