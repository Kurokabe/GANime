{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdff554-1c7e-422c-9c02-8e8a81c55d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1, 2, 3, 4, 5, 6, 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0a6e7c-eeae-4bca-812f-8e026f046894",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3820ac-31d6-4787-9994-ca6ed69bbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef5a9a2-1f2b-420a-bbed-24ff4ab9c9e6",
   "metadata": {},
   "source": [
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea3bca5d-ef9c-443f-aea0-f5d03fbc49a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "for device in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f493e5-3aea-42dd-b657-2e332e1d8afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ganime.data.experimental import ImageDataset, VideoDataset\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import display_images\n",
    "from ganime.model.vqgan_clean.experimental.net2net_v3 import Net2Net\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from pyprojroot.pyprojroot import here\n",
    "\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5e7fd-b6d4-4b78-9618-045075d125fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3366cc-e9a8-406e-9756-6710171eb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(here(\"configs/moving_mnist_image_transformer_huggingface.yaml\"))\n",
    "#cfg = omegaconf.OmegaConf.load(here(\"configs/default_transformer.yaml\"))\n",
    "batch_size = cfg[\"train\"][\"batch_size\"] \n",
    "global_batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "n_epochs = cfg[\"train\"][\"n_epochs\"]\n",
    "sample_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488cea1-b450-4620-9b82-9c7c7f859be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = 10000\n",
    "num_batch = dataset_length / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d4f1e-eaac-46d7-a4dd-c7a79adaed2f",
   "metadata": {},
   "source": [
    "def preprocess(element):\n",
    "    element = tf.reshape(element, (tf.shape(element)[0], tf.shape(element)[1], tf.shape(element)[2], 3))\n",
    "    element = tf.cast(element, tf.float32) / 255.0\n",
    "    first_frame = element[0,...]\n",
    "    last_frame = element[2,...]\n",
    "    \n",
    "    y = element[0:3,...]\n",
    "    \n",
    "    return {\"first_frame\": first_frame, \"last_frame\": last_frame, \"y\": y, \"n_frames\": tf.shape(element)[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c80d4-f55b-4934-991f-f890bbde5956",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob = 0.0 #0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16aece-063d-4e14-bae9-148634bca1a6",
   "metadata": {},
   "source": [
    "def preprocess(element):\n",
    "    element = tf.reshape(element, (tf.shape(element)[0], tf.shape(element)[1], tf.shape(element)[2], 3))\n",
    "    element = tf.cast(element, tf.float32) / 255.0\n",
    "    #num_elements_to_keep = tf.random.uniform(shape=(1,), minval=5, maxval=tf.shape(element)[0], dtype=tf.int32)\n",
    "    #remainder = tf.shape(element)[0] - num_elements_to_keep[0]\n",
    "    idx_to_keep = tf.random.uniform((tf.shape(element)[0],)) > drop_prob\n",
    "    element = element[idx_to_keep]\n",
    "    \n",
    "    #element = element[:10,...]\n",
    "    first_frame = element[0,...]\n",
    "    last_frame = element[-1,...]\n",
    "    \n",
    "    y = element\n",
    "    \n",
    "    return {\"first_frame\": first_frame, \"last_frame\": last_frame, \"y\": y, \"n_frames\": tf.shape(element)[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0cd38-1da8-493c-9824-19e7c143e0b2",
   "metadata": {},
   "source": [
    "def video_to_ragged(element):\n",
    "    element[\"y\"] = tf.RaggedTensor.from_tensor(tf.expand_dims(element[\"y\"], 0))\n",
    "    return element\n",
    "def squeeze_ragged(element):\n",
    "    element[\"y\"] = tf.squeeze(element[\"y\"], axis=1)\n",
    "    return element\n",
    "def to_tensor(element):\n",
    "    element[\"y\"] = element[\"y\"].to_tensor()\n",
    "    return element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed0f75-bd03-4b74-aa0f-e883132ea8a8",
   "metadata": {},
   "source": [
    "dataset = VideoDataset(\"../../../data/moving_mnist_tfrecords\").load()\n",
    "dataset = (dataset.shuffle(dataset_length, reshuffle_each_iteration=True)\n",
    "           .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "           #.map(video_to_ragged, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c7df1-0948-4f29-ab87-9169f028313a",
   "metadata": {},
   "source": [
    "train_size = int(dataset_length * 0.8)\n",
    "validation_size = int(dataset_length * 0.1)\n",
    "test_size = int(dataset_length * 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8fb4f-6386-472b-ab4c-2ca904888487",
   "metadata": {},
   "source": [
    "train_ds = dataset.take(train_size)#.batch(global_batch_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)#.batch(global_batch_size)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)#.batch(global_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bd55b-a50d-4dc3-ac34-62d53015b0a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "train_sample_data = next(train_ds\n",
    "                          .padded_batch(batch_size)\n",
    "                          .prefetch(tf.data.AUTOTUNE).as_numpy_iterator())\n",
    "validation_sample_data = next(validation_ds.padded_batch(batch_size).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e9b1a4-e9e2-4b1b-b0ed-13d1836b8ba3",
   "metadata": {},
   "source": [
    "train_ds = (train_ds.apply(\n",
    "                        tf.data.experimental.dense_to_ragged_batch(batch_size=batch_size, drop_remainder=True))\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "validation_ds = (validation_ds.apply(\n",
    "                        tf.data.experimental.dense_to_ragged_batch(batch_size=batch_size, drop_remainder=True))\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "test_ds = (test_ds.apply(\n",
    "                        tf.data.experimental.dense_to_ragged_batch(batch_size=batch_size, drop_remainder=True))\n",
    "            .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1f5c5-e188-4d6c-95be-a3f988cd16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(element):\n",
    "    element = tf.reshape(element, (tf.shape(element)[0], tf.shape(element)[1], tf.shape(element)[2], 3))\n",
    "    element = tf.cast(element, tf.float32) / 255.0\n",
    "    n_frames = tf.shape(element)[0]\n",
    "    \n",
    "    remaining_frames = tf.reverse(tf.range(n_frames), axis=[0])\n",
    "    \n",
    "    idx_to_keep = tf.random.uniform((tf.shape(element)[0],)) > drop_prob\n",
    "    element = element[idx_to_keep]\n",
    "    remaining_frames = remaining_frames[idx_to_keep]\n",
    "    \n",
    "    element = element[:10,...]\n",
    "    first_frame = element[0,...]\n",
    "    last_frame = element[-1,...]\n",
    "    \n",
    "    y = element\n",
    "    \n",
    "    return {\"first_frame\": first_frame, \"last_frame\": last_frame, \"y\": y, \"n_frames\": tf.shape(element)[0], \"remaining_frames\": remaining_frames}\n",
    "def postprocess(batch):\n",
    "    min_frames = tf.reduce_min(batch[\"n_frames\"])\n",
    "    first_frame_idx = tf.constant(0)\n",
    "    frames_to_keep = min_frames - 2\n",
    "    \n",
    "    y = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
    "    remaining_frames = tf.TensorArray(tf.int32, size=0, dynamic_size=True, clear_after_read=False)\n",
    "    \n",
    "    for i in tf.range(tf.shape(batch[\"y\"])[0]):\n",
    "        num_frames = batch[\"n_frames\"][i]\n",
    "        last_frame_idx = num_frames - 1\n",
    "        all_indices = tf.range(1, num_frames - 1)\n",
    "        indices = tf.sort(tf.random.shuffle(all_indices)[:frames_to_keep])\n",
    "        indices = tf.concat([[first_frame_idx], indices, [last_frame_idx]], axis=0)\n",
    "        y = y.write(i, tf.gather(batch[\"y\"][i], indices))\n",
    "        remaining_frames = remaining_frames.write(i, tf.gather(batch[\"remaining_frames\"][i], indices))\n",
    "        \n",
    "    batch[\"remaining_frames\"] = remaining_frames.stack()\n",
    "    batch[\"y\"] = y.stack()\n",
    "    batch[\"n_frames\"] = tf.repeat(min_frames, tf.shape(batch[\"y\"])[0])\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604a9a9-0bc1-4167-838f-5566966efedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(\"../../../data/moving_mnist_tfrecords\").load()\n",
    "dataset = (dataset.shuffle(dataset_length, reshuffle_each_iteration=True)\n",
    "           .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2379e7-9bb0-46f6-bc7f-11f5197de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(dataset_length * 0.8)\n",
    "validation_size = int(dataset_length * 0.1)\n",
    "test_size = int(dataset_length * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1c5aa-84b8-4ae3-b6db-db4a433bcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(train_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d748166-e601-4cab-9605-3e126e10c4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sample_data = next(train_ds\n",
    "                          .padded_batch(sample_batch_size).map(postprocess)\n",
    "                          .prefetch(tf.data.AUTOTUNE).as_numpy_iterator())\n",
    "validation_sample_data = next(validation_ds.padded_batch(sample_batch_size).map(postprocess).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbbb77-4dfe-49d3-9ab5-8a2f82753ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds.padded_batch(global_batch_size, drop_remainder=True)\n",
    "            .map(postprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "validation_ds = (validation_ds.padded_batch(global_batch_size, drop_remainder=True)\n",
    "            .map(postprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "test_ds = (test_ds.padded_batch(global_batch_size, drop_remainder=True)\n",
    "            .map(postprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e67e5-bbf9-4cb2-815f-661061d15e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_data[\"n_frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3aaa8-b21d-47af-aa0b-e15b5bf97c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(train_sample_data[\"last_frame\"], 2, 4)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88e2d0-afb0-4f24-a515-c652bacc6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(train_sample_data[\"y\"], 2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e55e032-ffb2-4194-87c7-cec441f21947",
   "metadata": {},
   "source": [
    "train_ds = strategy.experimental_distribute_dataset(train_ds)\n",
    "validation_ds = strategy.experimental_distribute_dataset(validation_ds)\n",
    "test_ds = strategy.experimental_distribute_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95ea96-7064-48dd-81ce-320d48431d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.utils.callbacks import TensorboardVideo, get_logdir\n",
    "import os\n",
    "\n",
    "logdir = get_logdir(\"../../../logs/ganime/transformers\", experiment_name=\"mnist_video\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "tensorboard_video_callback = TensorboardVideo(logdir, train_sample_data, validation_sample_data)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=50,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "checkpointing = tf.keras.callbacks.ModelCheckpoint(os.path.join(logdir, \"checkpoint\", \"checkpoint\"), monitor='val_total_loss', save_best_only=True, save_weights_only=True)\n",
    "#callbacks = [tensorboard_callback, early_stopping, checkpointing, tensorboard_video_callback]\n",
    "callbacks = [tensorboard_callback, checkpointing, tensorboard_video_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95352d-e94f-44a2-8c9b-4fff40b4fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_sample_data[\"y\"][:,0,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428ecb3-01a8-4453-896f-71cf98fb8ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_data[\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc61700-6a55-41f2-8a22-05419f28f965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = Net2Net(**cfg[\"model\"], trainer_config=cfg[\"train\"], num_replicas=strategy.num_replicas_in_sync)\n",
    "    #model.build(train_sample_data[\"y\"].shape)#first_stage_model.build(train_sample_data[\"y\"].shape[1:])\n",
    "    model.first_stage_model.build(train_sample_data[\"y\"].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa12dd2-20a1-4760-b392-9f10eb3476a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5313ea-35c7-4f99-9413-10ed7771ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936da37-67cd-4b81-9744-2f4402db1376",
   "metadata": {
    "tags": []
   },
   "source": [
    "for i in range(10):\n",
    "    pbar = tqdm(train_ds)\n",
    "    for data in pbar:\n",
    "        output = strategy.run(model.train_step, args=(data,))\n",
    "        pbar.set_postfix(loss=output[\"loss\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5dd8b1-39db-4d97-bc84-6ae46631a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=validation_ds, epochs=cfg[\"train\"][\"n_epochs\"], callbacks=callbacks)\n",
    "#model.fit(train_ds, epochs=cfg[\"train\"][\"n_epochs\"], callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0cec6e-b287-49d9-8848-ed32d695e3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_videos = model(train_sample_data, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d399fa7-3a52-466d-a742-04f00816cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(generated_videos, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583a6a7-7d07-47fc-9b71-1d718f48ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(train_sample_data[\"y\"], 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59bbc9-96f5-4e93-80b2-ae760b068cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_z, indices = model.encode_to_z(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65336fd2-1a64-4635-ab2d-6275749d1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = model.first_stage_model.quantize.get_codebook_entry(\n",
    "    indices, shape=tf.shape(quant_z)\n",
    ")\n",
    "decoded = model.first_stage_model.decode(quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6751d91-e4d2-44f2-9778-8c5b23d698e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_images(model.first_stage_model(images)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab52bd5-c95e-4fc1-9009-76e1f7f6425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(generated_videos[:,0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576c96f-c0a6-401b-877a-5eaf7b69ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
