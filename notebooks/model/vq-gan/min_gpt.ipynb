{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c995bfd-ceef-4145-a103-c2a064be737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a9c822-ecf1-44b2-aaf6-c7122a777180",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f01a67a-1183-424a-8eda-986b6be4173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ganime.data.experimental import ImageDataset, VideoDataset\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import display_images\n",
    "from ganime.model.vqgan_clean.net2net import Net2Net\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from pyprojroot.pyprojroot import here\n",
    "#tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277a395f-1f54-4d91-be02-214f698f0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64804403-13f9-4157-9dbb-757df9448525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 01:33:59.391281: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-04 01:33:59.778982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22308 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:a1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b530068b-b80a-4553-b0bb-5ec609da7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(here(\"configs/moving_mnist_image_transformer.yaml\"))\n",
    "#cfg = omegaconf.OmegaConf.load(here(\"configs/default_transformer.yaml\"))\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0216592-8406-46fe-b5c9-bfb39ce04b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = 10000\n",
    "num_batch = dataset_length / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1ac55d-561c-4b99-92c9-f92547e4cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(element):\n",
    "    element = tf.reshape(element, (tf.shape(element)[0], tf.shape(element)[1], tf.shape(element)[2], 3))\n",
    "    element = tf.cast(element, tf.float32) / 255.0\n",
    "    first_frame = element[0:1,...]\n",
    "    last_frame = element[-1:,...]\n",
    "    \n",
    "    y = element[1:,...]\n",
    "    \n",
    "    first_last_frame = tf.concat([first_frame, last_frame], axis=0)\n",
    "    \n",
    "    return first_last_frame, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293f1357-eb57-4561-9f54-c10912f1dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(\"../../../data/moving_mnist_tfrecords\").load()\n",
    "dataset = dataset.shuffle(dataset_length, reshuffle_each_iteration=True).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b06c992-9332-4690-b5d3-0deb9de24c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(num_batch * 0.8)\n",
    "validation_size = int(num_batch * 0.1)\n",
    "test_size = int(num_batch * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf5e800-4917-4873-bfe5-bf6a69ab3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(train_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210fd67e-fc3a-4f1b-a4b9-7c19a8032940",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_data = next(train_ds.as_numpy_iterator())\n",
    "validation_sample_data = next(validation_ds.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036a1a00-817c-4e76-8d13-d1b926ae9561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 19, 64, 64, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d8b4d9-86ec-42cc-bba8-9249a08423e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 128, 16, 16) = 32768 dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5b05c349254353a3735f0d258ecf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 01:34:12.856608: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-04 01:34:13.972949: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = Net2Net(**cfg[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c1ac4-80ac-41cc-aacf-a4730390e4de",
   "metadata": {},
   "source": [
    "lrs = [model.scheduled_lrs(i) for i in range(int(num_batch) * 500)]\n",
    "xs = np.linspace(0, 500, len(lrs))\n",
    "plt.plot(xs, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aa7cedb-d229-415e-9162-b4ac9dc89fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.utils.callbacks import TensorboardVideo, get_logdir\n",
    "import os\n",
    "\n",
    "logdir = get_logdir(\"../../../logs/ganime/\", experiment_name=\"transformer_mnist_video\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "tensorboard_video_callback = TensorboardVideo(logdir, train_sample_data, validation_sample_data)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=50,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "checkpointing = tf.keras.callbacks.ModelCheckpoint(os.path.join(logdir, \"checkpoint\", \"checkpoint\"), monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
    "callbacks = [tensorboard_callback, early_stopping, checkpointing, tensorboard_video_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a32b17-f47a-4762-ae3b-745bea1088ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with strategy.scope():\n",
    "#    model.compile(optimizer=tfa.optimizers.AdamW(\n",
    "#        learning_rate=1e-3, weight_decay=1e-4\n",
    "#    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd1eb60-ec5c-44f9-8836-574c3b52d039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model.first_stage_model.build(input_shape=(None, *train_sample_data[0].shape[2:]))\n",
    "    model.cond_stage_model.build(input_shape=(None, *train_sample_data[0].shape[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34201e-44e5-4ab3-85e6-ae866528db00",
   "metadata": {
    "tags": []
   },
   "source": [
    "with strategy.scope():\n",
    "    video = model(train_sample_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "570c37b7-1eaf-4eb4-8810-d21a110c5c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2579\u001b[0m, in \u001b[0;36mModel.summary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m \n\u001b[1;32m   2561\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m-> 2579\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2580\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2581\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2582\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2583\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[1;32m   2584\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2585\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   2586\u001b[0m     positions\u001b[38;5;241m=\u001b[39mpositions,\n\u001b[1;32m   2587\u001b[0m     print_fn\u001b[38;5;241m=\u001b[39mprint_fn,\n\u001b[1;32m   2588\u001b[0m     expand_nested\u001b[38;5;241m=\u001b[39mexpand_nested)\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6baf5-5362-4a48-bb7a-c361d466902b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=validation_ds, steps_per_epoch=10, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aab902-7a8e-41d0-9263-fe13d693c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(model.process_video(train_ds[0][0].astype(np.float32))[0], 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662edd9-8133-4f8f-b043-86c7a662e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(model.process_video(validation_ds[0][0].astype(np.float32))[0], 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11f8a2-f701-495f-b793-0a2de571e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_videos(model.process_video(test_ds[0][0].astype(np.float32))[0], 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5640c-d73e-4004-a279-5495803d3cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
