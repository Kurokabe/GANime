{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0efb334-4c96-4b8c-8229-aec9af0619fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"NCCL_DEBUG\"]=\"WARN\"\n",
    "#os.environ[\"NCCL_P2P_LEVEL\"]=\"NODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392c6e3a-c66e-4517-bcb9-4c90782e4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ba8145-34f8-4b06-bce5-d687df559773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5dfda8-24f9-4ca0-af11-45f54d1b8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ganime.data.experimental import ImageDataset, VideoDataset\n",
    "from ganime.model.vqgan_clean.vqgan import VQGAN\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import display_images\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pyprojroot.pyprojroot import here\n",
    "#tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed032479-6166-4ab9-8b49-ded5998344ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e064c018-2faa-4e6a-99e8-2293c7136a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 02:16:09.869746: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-12 02:16:10.344817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22302 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "778386dc-a6c1-4a06-9c4f-ccc4187b487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(here(\"configs/kny_image_full_vgg19.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024352ac-f325-49a3-8f11-847ee31a79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = len(tf.config.list_physical_devices(\"GPU\"))\n",
    "batch_size = cfg[\"trainer\"][\"batch_size\"] \n",
    "global_batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "n_epochs = cfg[\"trainer\"][\"n_epochs\"] \n",
    "sample_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ed457b-a5fd-4be5-b922-6d47499df6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_length = 34045 # KNY\n",
    "dataset_length = 310153 #KNY full\n",
    "#dataset_length = 20*10000 # MNIST\n",
    "num_batch = dataset_length / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8621b402-0616-4a58-a715-964bc47b6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1de37bb-e5ac-43dc-a457-e5adee689699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image, img_height=64, img_width=128):\n",
    "    cropped_image = tf.image.random_crop(image, size=[img_height, img_width, 3])\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8444b27-f776-4bd6-bc09-f1def624b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def random_jitter(image):\n",
    "    # Resizing to 72x142\n",
    "    image = tf.image.resize(image, [72, 142], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # Random cropping back to 64x128\n",
    "    image = random_crop(image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # Random mirroring\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbcf7304-151d-45dc-908d-fcdec7c96ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = tf.reshape(image, (tf.shape(image)[0], tf.shape(image)[1], 3))\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7604a9a9-0bc1-4167-838f-5566966efedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(\"../../../data/kny/images_tfrecords_full\").load()\n",
    "dataset = dataset.shuffle(dataset_length, reshuffle_each_iteration=True, seed=10).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2379e7-9bb0-46f6-bc7f-11f5197de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(dataset_length * 0.8)\n",
    "validation_size = int(dataset_length * 0.1)\n",
    "test_size = int(dataset_length * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d1c5aa-84b8-4ae3-b6db-db4a433bcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(train_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d748166-e601-4cab-9605-3e126e10c4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 02:16:20.959732: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 248932 of 310153\n",
      "2022-08-12 02:16:24.136894: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n"
     ]
    }
   ],
   "source": [
    "train_sample_data = next(train_ds\n",
    "                          .batch(sample_batch_size)\n",
    "                          .prefetch(tf.data.AUTOTUNE).as_numpy_iterator())\n",
    "validation_sample_data = next(validation_ds.batch(sample_batch_size).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bdbbb77-4dfe-49d3-9ab5-8a2f82753ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds.batch(global_batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "validation_ds = (validation_ds.batch(global_batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "test_ds = (test_ds.batch(global_batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c57b46-5920-4660-9791-7695b6656596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.utils.callbacks import TensorboardImage, get_logdir\n",
    "\n",
    "logdir = get_logdir(\"../../../logs/ganime/vqgan\", experiment_name=\"test_accumulation\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "tensorboard_image_callback = TensorboardImage(logdir, train_sample_data, validation_sample_data)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_total_loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=100,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "checkpointing = tf.keras.callbacks.ModelCheckpoint(os.path.join(logdir, \"checkpoint\", \"checkpoint\"), monitor='val_reconstruction_loss', save_best_only=True, save_weights_only=True)\n",
    "callbacks = [tensorboard_callback, tensorboard_image_callback, checkpointing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50eb6fd2-c042-4aa6-a536-2484e41d4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mean, train_var, train_std = dataset_statistics(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a62a144-c06f-417f-ac6a-c4a5c0120f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.visualization.images import display_true_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c6cf30-c4bb-4bf1-a942-cdc944532b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 512, 16, 16) = 131072 dimensions.\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    vqgan = VQGAN(**cfg[\"model\"], num_replicas=strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "637fe5ec-e9cf-496d-9daf-95456f867701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    gen_optimizer = tf.keras.optimizers.Adam(\n",
    "                learning_rate=cfg[\"trainer\"][\"gen_lr\"],\n",
    "                beta_1=cfg[\"trainer\"][\"gen_beta_1\"],\n",
    "                beta_2=cfg[\"trainer\"][\"gen_beta_2\"],\n",
    "                clipnorm=cfg[\"trainer\"][\"gen_clip_norm\"],\n",
    "    )\n",
    "    disc_optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=cfg[\"trainer\"][\"disc_lr\"],\n",
    "        beta_1=cfg[\"trainer\"][\"disc_beta_1\"],\n",
    "        beta_2=cfg[\"trainer\"][\"disc_beta_2\"],\n",
    "        clipnorm=cfg[\"trainer\"][\"disc_clip_norm\"],\n",
    "    )\n",
    "    vqgan.compile(gen_optimizer=gen_optimizer, disc_optimizer=disc_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d2c92-3443-406c-8f5e-4330bbe8cf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 02:17:16.826429: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 242564 of 310153\n",
      "2022-08-12 02:17:19.927648: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.\n",
      "2022-08-12 02:17:20.389982: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-08-12 02:17:24.663000: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15/Unknown - 67s 1s/step - total_loss: 9.6900 - reconstruction_loss: 1.6714 - vq_loss: 8.0186 - disc_loss: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = vqgan.fit(train_ds, validation_data=validation_ds, epochs=n_epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe4de7-8df4-4278-8a37-d211763c7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    x = train_sample_data[0]\n",
    "    generated = vqgan(x[:10])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb314da-0677-4daf-990a-ba35577a015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant, indices, _ = vqgan.encode(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d387f3-cfd4-47ad-99b3-a22a4bd588df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    quant = vqgan.quantize.get_codebook_entry(\n",
    "            [list(range(0, 128))], shape=(1, 8, 16, 128)\n",
    "    )\n",
    "\n",
    "    decoded = vqgan.decode(quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f29f8-4b44-4f16-9316-dafa2b2d498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.model.vqgan_clean.discriminator.model import NLayerDiscriminator\n",
    "with strategy.scope():\n",
    "    discriminator = NLayerDiscriminator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c620720-74d9-4efb-a8cb-bb3bdadccc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    vqgan.discriminator = discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef10a4-6899-40a1-b30c-bf582661a76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_input = tf.keras.layers.Input((256, 512, 6))\n",
    "model = tf.keras.Model(inputs=[model_input], outputs=vqgan.discriminator.call(model_input))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831e2bf-9801-4eaa-a5a8-67b06ac665c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec946a-6a21-426e-b0f6-5238c146f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = vqgan.discriminator(tf.concat([tf.ones((8, 256, 512, 3)), tf.image.resize(\n",
    "            train_sample_data[0], [256, 512], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
    "        )], axis=-1), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fba22-1197-47cd-bd51-d1324b4ba082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d9d8d3-a981-445b-ab7f-2c410b52c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [789, 799, 814, 816 , 819 ,825 ,794 ,766 ,760 ,747,752 ,787 ,742 ,795 ,752 ,774 ,789, \n",
    " 770 ,786 ,770 ,813 ,805 ,802 ,787 ,744 ,800 ,890 ,732 ,830 ,762 ,667 ,751, 821 , 1541 ,\n",
    " 784 ,801 ,788 ,768 ,768 ,787 ,726 ,705 ,647, 1102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76edfd2-0e1a-4103-914c-b34c0eee070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efab080-be28-43a0-9e66-cc4489c7a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086467c9-d625-4b51-9aee-e71519b36ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
