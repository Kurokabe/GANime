{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0efb334-4c96-4b8c-8229-aec9af0619fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "os.environ[\"NCCL_DEBUG\"]=\"WARN\"\n",
    "#os.environ[\"NCCL_P2P_LEVEL\"]=\"NODE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "392c6e3a-c66e-4517-bcb9-4c90782e4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2ba8145-34f8-4b06-bce5-d687df559773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c5dfda8-24f9-4ca0-af11-45f54d1b8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import omegaconf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ganime.data.experimental import ImageDataset, VideoDataset\n",
    "from ganime.model.vqgan_clean.vqgan import VQGAN\n",
    "from ganime.visualization.videos import display_videos\n",
    "from ganime.visualization.images import display_images\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pyprojroot.pyprojroot import here\n",
    "#tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed032479-6166-4ab9-8b49-ded5998344ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in tf.config.list_physical_devices(\"GPU\"):\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e064c018-2faa-4e6a-99e8-2293c7136a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "778386dc-a6c1-4a06-9c4f-ccc4187b487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = omegaconf.OmegaConf.load(here(\"configs/moving_mnist_image.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "024352ac-f325-49a3-8f11-847ee31a79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = len(tf.config.list_physical_devices(\"GPU\"))\n",
    "batch_size = cfg[\"trainer\"][\"batch_size\"] \n",
    "global_batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "n_epochs = cfg[\"trainer\"][\"n_epochs\"] \n",
    "sample_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38ed457b-a5fd-4be5-b922-6d47499df6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_length = 34045 # KNY\n",
    "#dataset_length = 310153 #KNY full\n",
    "dataset_length = 20*10000 # MNIST\n",
    "num_batch = dataset_length / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8621b402-0616-4a58-a715-964bc47b6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1de37bb-e5ac-43dc-a457-e5adee689699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(image, img_height=64, img_width=128):\n",
    "    cropped_image = tf.image.random_crop(image, size=[img_height, img_width, 3])\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8444b27-f776-4bd6-bc09-f1def624b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def random_jitter(image):\n",
    "    # Resizing to 72x142\n",
    "    image = tf.image.resize(image, [72, 142], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # Random cropping back to 64x128\n",
    "    image = random_crop(image)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # Random mirroring\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbcf7304-151d-45dc-908d-fcdec7c96ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image = tf.reshape(image, (tf.shape(image)[0], tf.shape(image)[1], 3))\n",
    "    #image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7604a9a9-0bc1-4167-838f-5566966efedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(\"../../../data/mnist_tfrecords\").load()\n",
    "dataset = dataset.shuffle(dataset_length, reshuffle_each_iteration=True, seed=10).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa2379e7-9bb0-46f6-bc7f-11f5197de55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(dataset_length * 0.8)\n",
    "validation_size = int(dataset_length * 0.1)\n",
    "test_size = int(dataset_length * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62d1c5aa-84b8-4ae3-b6db-db4a433bcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset.take(train_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d748166-e601-4cab-9605-3e126e10c4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sample_data = next(train_ds\n",
    "                          .batch(sample_batch_size)\n",
    "                          .prefetch(tf.data.AUTOTUNE).as_numpy_iterator())\n",
    "validation_sample_data = next(validation_ds.batch(sample_batch_size).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bdbbb77-4dfe-49d3-9ab5-8a2f82753ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds.batch(global_batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "validation_ds = (validation_ds.batch(global_batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "test_ds = (test_ds.batch(global_batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a62a144-c06f-417f-ac6a-c4a5c0120f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.visualization.images import display_true_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70c6cf30-c4bb-4bf1-a942-cdc944532b88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 512, 16, 16) = 131072 dimensions.\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    vqgan = VQGAN(**cfg[\"model\"], num_replicas=strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "637fe5ec-e9cf-496d-9daf-95456f867701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    gen_optimizer = tf.keras.optimizers.Adam(\n",
    "                learning_rate=cfg[\"trainer\"][\"gen_lr\"],\n",
    "                beta_1=cfg[\"trainer\"][\"gen_beta_1\"],\n",
    "                beta_2=cfg[\"trainer\"][\"gen_beta_2\"],\n",
    "                clipnorm=cfg[\"trainer\"][\"gen_clip_norm\"],\n",
    "    )\n",
    "    disc_optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=cfg[\"trainer\"][\"disc_lr\"],\n",
    "        beta_1=cfg[\"trainer\"][\"disc_beta_1\"],\n",
    "        beta_2=cfg[\"trainer\"][\"disc_beta_2\"],\n",
    "        clipnorm=cfg[\"trainer\"][\"disc_clip_norm\"],\n",
    "    )\n",
    "    vqgan.compile(gen_optimizer=gen_optimizer, disc_optimizer=disc_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17efcfe2-c348-4621-b17e-b67d42db0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganime.metrics.image import calculate_images_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dcfeb21-0f92-416e-b318-feeaacda15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(\"../../../data/mnist_tfrecords\").load()\n",
    "dataset = dataset.shuffle(dataset_length, reshuffle_each_iteration=True).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_ds = dataset.take(train_size)\n",
    "validation_ds = dataset.skip(train_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)\n",
    "test_ds = dataset.skip(train_size + validation_size).take(validation_size)#.padded_batch(global_batch_size).map(postprocess)\n",
    "\n",
    "train_ds = (train_ds.batch(batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "validation_ds = (validation_ds.batch(batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "test_ds = (test_ds.batch(batch_size, drop_remainder=True)\n",
    "            .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f18f20a8-db74-46d0-aca6-fc80b6cf6cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c095e7f71e4e1c962a88debbaec3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abbe113c6b747668ae7deada1bb0b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a04321e11f469eb9bc61d899e79004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed2cf5e44ff4f8ca00e35656fb98b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919c035a10994f2fbcfda6b44ac3e7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'fid': 18.115365820305104, 'ssim': 0.83215195, 'psnr': 23.687765},\n",
       " {'fid': 18.127795343861955, 'ssim': 0.8321791, 'psnr': 23.685871},\n",
       " {'fid': 17.983672100023036, 'ssim': 0.83247787, 'psnr': 23.699646},\n",
       " {'fid': 18.04111774504951, 'ssim': 0.8317932, 'psnr': 23.68214},\n",
       " {'fid': 18.159041522908865, 'ssim': 0.83215183, 'psnr': 23.69139}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_test = [calculate_images_metrics(test_ds, vqgan, validation_size // batch_size) for i in range(5)]\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bca5b98-cac1-4daa-8abd-46548cc18470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8da4edf7d44256aa3cfc773d8e5f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6494356816b4007881b089ef4bdf065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d520fce7354a6e938f50fead423ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9234bf968a94a9bb6f2b75085df4e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8ac61333da4f5681359714519e3bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'fid': 17.798508110873158, 'ssim': 0.8321389, 'psnr': 23.689665},\n",
       " {'fid': 17.82400717736511, 'ssim': 0.83215195, 'psnr': 23.690237},\n",
       " {'fid': 17.834273862523, 'ssim': 0.83214396, 'psnr': 23.689932},\n",
       " {'fid': 17.853948306492335, 'ssim': 0.83206, 'psnr': 23.688257},\n",
       " {'fid': 17.84624170945504, 'ssim': 0.832055, 'psnr': 23.68829}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_train = [calculate_images_metrics(train_ds, vqgan, train_size // batch_size) for i in range(5)]\n",
    "metrics_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7381aa58-432e-4b63-a1c3-6b63fccce68e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
